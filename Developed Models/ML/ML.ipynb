{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e88642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "from transformers import BertTokenizer,BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "# from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "# from ignite.metrics import Accuracy, Loss\n",
    "# from ignite.engine.engine import Engine, State, Events\n",
    "# from ignite.handlers import EarlyStopping\n",
    "# from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n",
    "# from ignite.utils import convert_tensor\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "import random\n",
    "import os\n",
    "from urllib import request\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer , TrainingArguments\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, PreTrainedModel\n",
    "from transformers import BertModel, BertPreTrainedModel, BertForMaskedLM\n",
    "from transformers.models.bert.modeling_bert import BertOnlyMLMHead, BertLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3bfc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import argparse\n",
    "import csv\n",
    "from scipy.sparse import *\n",
    "import pandas as pd\n",
    "import regex \n",
    "from sklearn.base import TransformerMixin\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.util import ngrams\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e835675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer, BertForMaskedLM,AutoModelForMaskedLM,AutoModel,AutoTokenizer,AutoConfig\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import utils\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545e3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(y, y_pred):\n",
    "    accuracy = metrics.accuracy_score(y, y_pred)\n",
    "    precision = metrics.precision_score(y, y_pred, average='weighted')\n",
    "    recall = metrics.recall_score(y, y_pred, average='weighted')\n",
    "    f_score = metrics.f1_score(y, y_pred, average='weighted')\n",
    "    print('Accuracy: %.3f\\nPrecision: %.3f\\nRecall: %.3f\\nF_score: %.3f\\n'\n",
    "          % (accuracy, precision, recall, f_score))\n",
    "    print(metrics.classification_report(y, y_pred))\n",
    "    return accuracy, precision, recall, f_score\n",
    "\n",
    "\n",
    "\n",
    "def plot_coefficients(classifier, feature_names, top_features=20, plot_name=\"/bow_models/bow_binary_\"):\n",
    "    # Get the top most positive/negative coefficients\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    x_names = [feature_names[feature] for feature in top_coefficients]\n",
    "\n",
    "    # Plot the coefficients\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    plt.xticks(np.arange(0, 2 * top_features), x_names, rotation=30, ha='right')\n",
    "    plt.ylabel(\"Coefficient Value\")\n",
    "    plt.title(\"Visualising the top %d features taken up by an SVM model\" % top_features)\n",
    "    to_save_filename = path + \"/plots/\" + plot_name + \"top%d_coefficients.png\" % top_features\n",
    "    plt.savefig(to_save_filename)\n",
    "    print(\"Coefficients' visualisation saved to %s\\n\" % to_save_filename)\n",
    "\n",
    "def get_regularization_params(a=-1, b=1, c=3, d=1, e=5):\n",
    "    reg_range = np.outer(np.logspace(a, b, c), np.array([d, e]))\n",
    "    reg_range = reg_range.flatten()\n",
    "    return reg_range\n",
    "\n",
    "\n",
    "def grid_classifier(x_train, y_train, x_test, y_test, model, parameters,\n",
    "                    make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    grid = GridSearchCV(estimator=model, param_grid=parameters, verbose=0)\n",
    "    grid.fit(x_train, y_train)\n",
    "    sorted(grid.cv_results_.keys())\n",
    "    classifier = grid.best_estimator_\n",
    "    if make_feature_analysis:\n",
    "        plot_coefficients(classifier, feature_names, top_features, plot_name)\n",
    "    y_hat = classifier.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)\n",
    "\n",
    "# Method to print the header of the currently running model\n",
    "def print_model_title(name):\n",
    "    print(\"\\n==================================================================\")\n",
    "    print('{:>20}'.format(name))\n",
    "    print(\"==================================================================\\n\")\n",
    "\n",
    "\n",
    "def linear_svm_grid(x_train, y_train, x_test, y_test, class_ratio,\n",
    "               make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    print_model_title(\"Linear SVM\")\n",
    "    C_range = get_regularization_params()\n",
    "    parameters = {'C': C_range}\n",
    "    linear_svm = LinearSVC(C=1.0, class_weight=class_ratio, penalty='l2')\n",
    "    grid_classifier(x_train, y_train, x_test, y_test, linear_svm, parameters,\n",
    "                    make_feature_analysis, feature_names, top_features, plot_name)\n",
    "\n",
    "\n",
    "def nonlinear_svm_grid(x_train, y_train, x_test, y_test, class_ratio,\n",
    "                  make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    print_model_title(\"Nonlinear SVM\")\n",
    "    C_range = get_regularization_params(a=-1, b=0, c=2, d=1, e=5)\n",
    "    gamma_range = get_regularization_params(a=-2, b=-1, c=2, d=1, e=5)\n",
    "    parameters = {'kernel': ['rbf'], 'C': C_range, 'gamma': gamma_range}\n",
    "    nonlinear_svm = SVC(class_weight=class_ratio)\n",
    "    grid_classifier(x_train, y_train, x_test, y_test, nonlinear_svm, parameters,\n",
    "                    make_feature_analysis, feature_names, top_features, plot_name)\n",
    "\n",
    "\n",
    "def logistic_regression_grid(x_train, y_train, x_test, y_test, class_ratio,\n",
    "                        make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    print_model_title(\"Logistic Regression\")\n",
    "    C_range = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    parameters = {'C': C_range}\n",
    "    log_regr = LogisticRegression(C=1.0, class_weight=class_ratio, penalty='l2')\n",
    "    grid_classifier(x_train, y_train, x_test, y_test, log_regr, parameters,\n",
    "                    make_feature_analysis, feature_names, top_features, plot_name)\n",
    "\n",
    "\n",
    "def linear_svm(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n",
    "    print_model_title(\"Linear SVM\")\n",
    "    svm = LinearSVC(C=0.01, class_weight=class_ratio, penalty='l2')\n",
    "    svm.fit(x_train, y_train)\n",
    "    y_hat = svm.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)\n",
    "    # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/svm_model_bin.sav'\n",
    "    # joblib.dump(svm, filename)\n",
    "\n",
    "\n",
    "def logistic_regression(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n",
    "    print_model_title(\"Logistic Regression\")\n",
    "    regr = LogisticRegression(C=0.01, class_weight=class_ratio, penalty='l2')\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_hat = regr.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)\n",
    "    # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "    # joblib.dump(regr, filename)\n",
    "\n",
    "\n",
    "def random_forest(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n",
    "  print_model_title(\"Random Forest\")\n",
    "  rf = RandomForestClassifier(n_estimators=400, random_state=11)\n",
    "  rf.fit(x_train, y_train)\n",
    "  y_hat = rf.predict(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "def xg_boost(x_train, y_train, x_test, y_test):\n",
    "  print_model_title(\"XGBoost\")\n",
    "  xgb_model =XGBClassifier(max_depth=6, n_estimators=1000)\n",
    "  xgb_model .fit(x_train, y_train)\n",
    "  y_hat = xgb_model .predict(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "\n",
    "def xg_boost_focal_loss(x_train, y_train, x_test, y_test):\n",
    "  print_model_title(\"XGBoost Focal\")\n",
    "  xgboster_focal = imb_xgb(special_objective='focal')\n",
    "  CV_focal_booster = GridSearchCV(xgboster_focal, {\"focal_gamma\":[1.0,1.5,2.0,2.5,3.0]})\n",
    "  CV_focal_booster.fit(x_train, y_train)\n",
    "  opt_focal_booster = CV_focal_booster.best_estimator_\n",
    "  # xgb_model .fit(x_train, y_train)\n",
    "  y_hat = opt_focal_booster.predict_determine(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "def xg_boost_weighted_loss(x_train, y_train, x_test, y_test):\n",
    "  print_model_title(\"XGBoost Weighted\")\n",
    "  xgboster_focal = imb_xgb(special_objective='weighted')\n",
    "  CV_focal_booster = GridSearchCV(xgboster_focal, {\"imbalance_alpha\":[1.5,2.0,2.5,3.0,4.0]})\n",
    "  CV_focal_booster.fit(x_train, y_train)\n",
    "  opt_focal_booster = CV_focal_booster.best_estimator_\n",
    "  # xgb_model .fit(x_train, y_train)\n",
    "  y_hat = opt_focal_booster.predict_determine(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "\n",
    "def feature_selection(x_train, y_train, x_test, y_test):\n",
    "    print(\"Feature selection with LinearSVC\")\n",
    "    model = LinearSVC(C=0.1, penalty='l2')\n",
    "    rfe = RFE(model, 5)\n",
    "    best_features_model = rfe.fit(x_train, y_train)\n",
    "    y_hat = best_features_model.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)\n",
    "\n",
    "\n",
    "def ensemble_stacked(x_train, y_train, x_test, y_test):\n",
    "  print_model_title(\"Ensemble Stacked Classifiers\")\n",
    "  estimators = [ ('lr',LogisticRegression(C=0.01, class_weight='balanced', penalty='l2')),('xgb',XGBClassifier(max_depth=16, n_estimators=1000)),('svm_linear',LinearSVC(C=0.01, class_weight='balanced', penalty='l2')),('rf', RandomForestClassifier(n_estimators=10, random_state=42))]\n",
    "  from sklearn.ensemble import StackingClassifier\n",
    "  clf = StackingClassifier(\n",
    "      estimators=estimators )\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_hat = clf .predict(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "def voting_classifiers(x_train, y_train, x_test, y_test,voting_type='hard'):\n",
    "  print_model_title(\"Voting Classifier\")\n",
    "  estimators = [ ('lr',LogisticRegression(C=0.01, class_weight='balanced', penalty='l2')),('xgb',XGBClassifier(max_depth=16, n_estimators=1000)),('svm_linear',LinearSVC(C=0.01, class_weight='balanced', penalty='l2')),('rf', RandomForestClassifier(n_estimators=10, random_state=42))]\n",
    "  from sklearn.ensemble import StackingClassifier\n",
    "  clf = VotingClassifier(\n",
    "      estimators=estimators , voting=voting_type)\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_hat = clf .predict(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "def Bagging_Classifier_LR(x_train, y_train, x_test, y_test):\n",
    "  print_model_title(\"Bagging Calssifier LR\")\n",
    " \n",
    "  clf =BaggingClassifier(base_estimator=LogisticRegression(C=0.01, class_weight='balanced', penalty='l2'),\n",
    "                       n_estimators=10, random_state=42)\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_hat = clf .predict(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "\n",
    "def Bagging_Classifier_SVM(x_train, y_train, x_test, y_test):\n",
    "  print_model_title(\"Bagging Calssifier SVM\")\n",
    " \n",
    "  clf =BaggingClassifier(base_estimator=LinearSVC(C=0.01, class_weight='balanced', penalty='l2'),\n",
    "                       n_estimators=10, random_state=42)\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_hat = clf .predict(x_test)\n",
    "  print_statistics(y_test, y_hat)\n",
    "  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n",
    "  # joblib.dump(regr, filename)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def gradient_boosting(x_train, y_train, x_test, y_test):\n",
    "  print_model_title(\"Gradient Boosting\")\n",
    " \n",
    "  clf =GradientBoostingClassifier(n_estimators=100, learning_rate=0.01,max_depth=30, random_state=42)\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_hat = clf .predict(x_test)\n",
    "  print_statistics(y_test, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b5fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1630b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1cba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # print(token_embeddings.shape)\n",
    "    # token_vecs_cat = []\n",
    "    # for token in token_embeddings:\n",
    "    #   cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19ae8aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained('UBC-NLP/MARBERTv2')\n",
    "model=AutoModel.from_pretrained(('UBC-NLP/MARBERTv2'),output_hidden_states = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09a03cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/ahmed/Downloads/Imagenet_VLCQ/Nadi/Dataset/NADI2022_Subtask2_TRAIN.tsv', sep='\\t', lineterminator='\\n')\n",
    "test = pd.read_csv('/home/ahmed/Downloads/Imagenet_VLCQ/Nadi/Dataset/NADI2022_Subtask2_DEV.tsv', sep='\\t', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68af0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns = {'#2_content':'text', '#3_label':'label'}, inplace = True)\n",
    "test.rename(columns = {'#2_content':'text', '#3_label':'label'}, inplace = True)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'].values)\n",
    "le = LabelEncoder()\n",
    "\n",
    "test['label'] = le.fit_transform(test['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6715dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "wordvec_arrays = np.zeros((len(train['text']), 768)) \n",
    "i=0\n",
    "# for i in range(len(tokenized_tweet)):\n",
    "#     # print(i)\n",
    "    \n",
    "\n",
    "\n",
    "for text in train['text'].values:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    def word_vector(tokens, size):\n",
    "      vec = np.zeros(size).reshape((1, size))\n",
    "      count = 0\n",
    "      for word in list_token_embeddings:\n",
    "          try:\n",
    "              # print(model_w2v[word].shape)\n",
    "              vec += np.array(word).reshape((1, size))\n",
    "              count += 1.\n",
    "          except KeyError:  # handling the case where the token is not in vocabulary\n",
    "              continue\n",
    "      if count != 0:\n",
    "          vec /= count\n",
    "      return vec\n",
    "    wordvec_arrays[i,:] = word_vector(list_token_embeddings, 768)\n",
    "    i=i+1\n",
    "    # print(len(list_token_embeddings))\n",
    "    # target_word_embeddings.append(np.array(list_token_embeddings))\n",
    "    \n",
    "    # # Find the position 'bank' in list of tokens\n",
    "    # word_index = tokenized_text.index('bank')\n",
    "    # # Get the embedding for bank\n",
    "    # word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    # target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "164b4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df_new = pd.DataFrame(wordvec_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a63b6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "wordvec_arrays = np.zeros((len(test['text']), 768)) \n",
    "i=0\n",
    "# for i in range(len(tokenized_tweet)):\n",
    "#     # print(i)\n",
    "    \n",
    "\n",
    "\n",
    "for text in test['text'].values:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    def word_vector(tokens, size):\n",
    "      vec = np.zeros(size).reshape((1, size))\n",
    "      count = 0\n",
    "      for word in list_token_embeddings:\n",
    "          try:\n",
    "              # print(model_w2v[word].shape)\n",
    "              vec += np.array(word).reshape((1, size))\n",
    "              count += 1.\n",
    "          except KeyError:  # handling the case where the token is not in vocabulary\n",
    "              continue\n",
    "      if count != 0:\n",
    "          vec /= count\n",
    "      return vec\n",
    "    wordvec_arrays[i,:] = word_vector(list_token_embeddings, 768)\n",
    "    i=i+1\n",
    "    # print(len(list_token_embeddings))\n",
    "    # target_word_embeddings.append(np.array(list_token_embeddings))\n",
    "    \n",
    "    # # Find the position 'bank' in list of tokens\n",
    "    # word_index = tokenized_text.index('bank')\n",
    "    # # Get the embedding for bank\n",
    "    # word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    # target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fefd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c88a3796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b311ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df_test= pd.DataFrame(wordvec_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cadf5f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordvec_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d15baed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b252857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "   Gradient Boosting\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.468\n",
      "Precision: 0.456\n",
      "Recall: 0.468\n",
      "F_score: 0.455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.47       190\n",
      "           1       0.34      0.21      0.26       113\n",
      "           2       0.49      0.62      0.55       197\n",
      "\n",
      "    accuracy                           0.47       500\n",
      "   macro avg       0.44      0.43      0.43       500\n",
      "weighted avg       0.46      0.47      0.45       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting(wordvec_df_new,train['label'],wordvec_df_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb83e402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "Bagging Calssifier SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.564\n",
      "Precision: 0.554\n",
      "Recall: 0.564\n",
      "F_score: 0.554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.62       190\n",
      "           1       0.45      0.30      0.36       113\n",
      "           2       0.59      0.60      0.60       197\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.54      0.53      0.53       500\n",
      "weighted avg       0.55      0.56      0.55       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bagging_Classifier_SVM(wordvec_df_new,train['label'],wordvec_df_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77cc76ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "Bagging Calssifier LR\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.526\n",
      "Precision: 0.533\n",
      "Recall: 0.526\n",
      "F_score: 0.529\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.55       190\n",
      "           1       0.38      0.43      0.40       113\n",
      "           2       0.59      0.56      0.58       197\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.51      0.51      0.51       500\n",
      "weighted avg       0.53      0.53      0.53       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bagging_Classifier_LR(wordvec_df_new,train['label'],wordvec_df_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d81a239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_classifiers(wordvec_df_new,train['label'],wordvec_df_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c36218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_stacked(wordvec_df_new,train['label'],wordvec_df_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_boost(wordvec_df_new,train['label'],wordvec_df_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc3586af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "       Random Forest\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.556\n",
      "Precision: 0.559\n",
      "Recall: 0.556\n",
      "F_score: 0.497\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.69      0.61       190\n",
      "           1       0.57      0.04      0.07       113\n",
      "           2       0.56      0.73      0.63       197\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.56      0.48      0.44       500\n",
      "weighted avg       0.56      0.56      0.50       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(wordvec_df_new,train['label'],wordvec_df_test,test['label'],class_ratio='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9c66cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      " Logistic Regression\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.528\n",
      "Precision: 0.543\n",
      "Recall: 0.528\n",
      "F_score: 0.532\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56       190\n",
      "           1       0.39      0.49      0.43       113\n",
      "           2       0.63      0.51      0.56       197\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.52      0.52      0.52       500\n",
      "weighted avg       0.54      0.53      0.53       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(wordvec_df_new,train['label'],wordvec_df_test,test['label'],class_ratio='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01393b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "          Linear SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.568\n",
      "Precision: 0.561\n",
      "Recall: 0.568\n",
      "F_score: 0.558\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61       190\n",
      "           1       0.49      0.31      0.38       113\n",
      "           2       0.60      0.61      0.61       197\n",
      "\n",
      "    accuracy                           0.57       500\n",
      "   macro avg       0.55      0.53      0.53       500\n",
      "weighted avg       0.56      0.57      0.56       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_svm(wordvec_df_new,train['label'],wordvec_df_test,test['label'],class_ratio='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddcdf561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      " Logistic Regression\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.582\n",
      "Precision: 0.601\n",
      "Recall: 0.582\n",
      "F_score: 0.589\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65       190\n",
      "           1       0.36      0.45      0.40       113\n",
      "           2       0.67      0.62      0.64       197\n",
      "\n",
      "    accuracy                           0.58       500\n",
      "   macro avg       0.57      0.56      0.56       500\n",
      "weighted avg       0.60      0.58      0.59       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_grid(wordvec_df_new,train['label'],wordvec_df_test,test['label'],class_ratio='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e8493d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "       Nonlinear SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.572\n",
      "Precision: 0.577\n",
      "Recall: 0.572\n",
      "F_score: 0.574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63       190\n",
      "           1       0.38      0.42      0.40       113\n",
      "           2       0.64      0.60      0.62       197\n",
      "\n",
      "    accuracy                           0.57       500\n",
      "   macro avg       0.55      0.55      0.55       500\n",
      "weighted avg       0.58      0.57      0.57       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nonlinear_svm_grid(wordvec_df_new,train['label'],wordvec_df_test,test['label'],class_ratio='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a9abfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "          Linear SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.610\n",
      "Precision: 0.605\n",
      "Recall: 0.610\n",
      "F_score: 0.607\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68       190\n",
      "           1       0.42      0.38      0.40       113\n",
      "           2       0.66      0.65      0.65       197\n",
      "\n",
      "    accuracy                           0.61       500\n",
      "   macro avg       0.58      0.58      0.58       500\n",
      "weighted avg       0.60      0.61      0.61       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_svm_grid(wordvec_df_new,train['label'],wordvec_df_test,test['label'],class_ratio='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b745971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
