{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert-base-arabertv02-twitter_multiple losses_w_imablancesampler.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"3b3239a78c814687864bc1795ae3efce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5444fb225310472bbd78218c7a8a0b9b","IPY_MODEL_26c3b9346d3241928c6613610abf95f4","IPY_MODEL_3f028b3c2f1c4545b9383b5040e3344a"],"layout":"IPY_MODEL_c3374fcc4b0743ecab23fc0e1d6feb0e"}},"5444fb225310472bbd78218c7a8a0b9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3771eb29729f4bd7a0d46131f6c76a69","placeholder":"​","style":"IPY_MODEL_ba5e6aa9054d48eab6fa7707fec6a336","value":"Downloading tokenizer_config.json: 100%"}},"26c3b9346d3241928c6613610abf95f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb79b1cfe034281bc0af5dabbaec1aa","max":476,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f612ce38e39b432ea6817e9f7d574366","value":476}},"3f028b3c2f1c4545b9383b5040e3344a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6132e20194464c928d0a90e87b92d372","placeholder":"​","style":"IPY_MODEL_5b6f775f04d646468667678426071c54","value":" 476/476 [00:00&lt;00:00, 14.1kB/s]"}},"c3374fcc4b0743ecab23fc0e1d6feb0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3771eb29729f4bd7a0d46131f6c76a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba5e6aa9054d48eab6fa7707fec6a336":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb79b1cfe034281bc0af5dabbaec1aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f612ce38e39b432ea6817e9f7d574366":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6132e20194464c928d0a90e87b92d372":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b6f775f04d646468667678426071c54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17efa215547641c989bd0ec6810de579":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21af0283221b43d5afe13bba23ce19b1","IPY_MODEL_df328f1dc29b433bab207cf0579b4869","IPY_MODEL_b4b673d4fde947dd985f6a614c50f6c5"],"layout":"IPY_MODEL_382194c6aafc42ab84076a21b7b3daec"}},"21af0283221b43d5afe13bba23ce19b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3af4f9dbf2248d4a3229a03d8ada83b","placeholder":"​","style":"IPY_MODEL_fc57b3ae3c4a42feb9092f6b6b6dad00","value":"Downloading vocab.txt: 100%"}},"df328f1dc29b433bab207cf0579b4869":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6be05783df994f4fbde921dbc2c7b821","max":750551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_888d1f22517a4dbbb4d8fe2ee4e3967a","value":750551}},"b4b673d4fde947dd985f6a614c50f6c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_525e3abb913e40ab8a4023ba57deac4a","placeholder":"​","style":"IPY_MODEL_d0fbf9310f554a03a8194c046853f74c","value":" 733k/733k [00:00&lt;00:00, 2.26MB/s]"}},"382194c6aafc42ab84076a21b7b3daec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3af4f9dbf2248d4a3229a03d8ada83b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc57b3ae3c4a42feb9092f6b6b6dad00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6be05783df994f4fbde921dbc2c7b821":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"888d1f22517a4dbbb4d8fe2ee4e3967a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"525e3abb913e40ab8a4023ba57deac4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0fbf9310f554a03a8194c046853f74c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9188ca9e079a4af3b1acb7449f8afaf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_327db4a275814c40801527ac9afe0120","IPY_MODEL_a04bf09ddeed4439a306fe70ea986d5a","IPY_MODEL_890892d949044f8a9d0313446d64b02a"],"layout":"IPY_MODEL_67bf3e8bc5c2400a8cb12916ba2bca2b"}},"327db4a275814c40801527ac9afe0120":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2070565993f444148a250a5d1dc265ab","placeholder":"​","style":"IPY_MODEL_f4a28413b19c4c5cb53c844973838132","value":"Downloading tokenizer.json: 100%"}},"a04bf09ddeed4439a306fe70ea986d5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c63970cc01b646bc909c84836742299c","max":1252935,"min":0,"orientation":"horizontal","style":"IPY_MODEL_006d192b3b90452ca1a82ad34b8804ae","value":1252935}},"890892d949044f8a9d0313446d64b02a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_836f302ff3d34c488ab3016c5d08cc44","placeholder":"​","style":"IPY_MODEL_778be036c7dd4af29077e770858d879d","value":" 1.19M/1.19M [00:00&lt;00:00, 2.95MB/s]"}},"67bf3e8bc5c2400a8cb12916ba2bca2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2070565993f444148a250a5d1dc265ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4a28413b19c4c5cb53c844973838132":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c63970cc01b646bc909c84836742299c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"006d192b3b90452ca1a82ad34b8804ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"836f302ff3d34c488ab3016c5d08cc44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"778be036c7dd4af29077e770858d879d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8046d1f0d1a4e02b1deea9256af1616":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35398e7a36a0430882ebd3cf02b43bcd","IPY_MODEL_aee4de5dcab74524837dc31aa4b28d5d","IPY_MODEL_e53fb0b974524a5382642fe62741b55c"],"layout":"IPY_MODEL_22239d685edb474093acd9cdb8849933"}},"35398e7a36a0430882ebd3cf02b43bcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5a06db0669c4ecb849e85c67fee8d62","placeholder":"​","style":"IPY_MODEL_a44b5438751e446cadcf8a9b018da3b2","value":"Downloading special_tokens_map.json: 100%"}},"aee4de5dcab74524837dc31aa4b28d5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_919dfe16bb0448b0b77ea2497d292094","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c06f7024f99432882a27bff32081f3f","value":112}},"e53fb0b974524a5382642fe62741b55c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0f3775f8e7c46e2bec1c487b602dd8f","placeholder":"​","style":"IPY_MODEL_f26346735afb460d84715f2e4a6ba186","value":" 112/112 [00:00&lt;00:00, 3.17kB/s]"}},"22239d685edb474093acd9cdb8849933":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5a06db0669c4ecb849e85c67fee8d62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a44b5438751e446cadcf8a9b018da3b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"919dfe16bb0448b0b77ea2497d292094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c06f7024f99432882a27bff32081f3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0f3775f8e7c46e2bec1c487b602dd8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f26346735afb460d84715f2e4a6ba186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4380a418c08b48909d3697c8cd0bd0ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86ab8b87c3f34f54b28b5348e3758bd0","IPY_MODEL_a57ef8c59f5f47399b379f7211b7c668","IPY_MODEL_9dccc24494f84a2e884d5c10a4b328de"],"layout":"IPY_MODEL_df1f65971f6e44908dca4503b7039e63"}},"86ab8b87c3f34f54b28b5348e3758bd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_916d8e268a0e478899e51d8fb11e1369","placeholder":"​","style":"IPY_MODEL_1d7a4bef4a8443b58c83f9ee4fcb8f25","value":"Downloading config.json: 100%"}},"a57ef8c59f5f47399b379f7211b7c668":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cf3d0a389714fde8ea655aa9813e792","max":667,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c62103be1a034b34bf0c6a92ffb3ef4e","value":667}},"9dccc24494f84a2e884d5c10a4b328de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6a0f0cf96774b7eac341848ea33f305","placeholder":"​","style":"IPY_MODEL_3ecf243994cb4d70992c2405004d8d8b","value":" 667/667 [00:00&lt;00:00, 17.5kB/s]"}},"df1f65971f6e44908dca4503b7039e63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"916d8e268a0e478899e51d8fb11e1369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d7a4bef4a8443b58c83f9ee4fcb8f25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cf3d0a389714fde8ea655aa9813e792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c62103be1a034b34bf0c6a92ffb3ef4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6a0f0cf96774b7eac341848ea33f305":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ecf243994cb4d70992c2405004d8d8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"263fed89e8d442918e8163073fab3d7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c15e2d5a4c8488cab38bd293523a1be","IPY_MODEL_8589e42de6394a9e888e35d5aaff991b","IPY_MODEL_35c63fbdec384cafbe47ddaee2cd6784"],"layout":"IPY_MODEL_123787861988452db782976fb2e17b19"}},"9c15e2d5a4c8488cab38bd293523a1be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a1d0910d928495a8eaa9a2b6714230d","placeholder":"​","style":"IPY_MODEL_18133af03efb4498a826b2ff2ffbf2c5","value":"Downloading pytorch_model.bin: 100%"}},"8589e42de6394a9e888e35d5aaff991b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08704f0b3a5e4a1f89998cb5ff91de00","max":541120363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a7722b23b594201b37c6b2d0eb55e87","value":541120363}},"35c63fbdec384cafbe47ddaee2cd6784":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8dd386c36c44240ae8e76040c57c02a","placeholder":"​","style":"IPY_MODEL_7c1d182ca084488e8e7630b9393e0288","value":" 516M/516M [00:10&lt;00:00, 62.6MB/s]"}},"123787861988452db782976fb2e17b19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a1d0910d928495a8eaa9a2b6714230d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18133af03efb4498a826b2ff2ffbf2c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08704f0b3a5e4a1f89998cb5ff91de00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a7722b23b594201b37c6b2d0eb55e87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8dd386c36c44240ae8e76040c57c02a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c1d182ca084488e8e7630b9393e0288":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install sentencepiece\n","!pip  install transformers\n","!pip install pytorch-ignite\n","!pip install datasets\n","\n"],"metadata":{"id":"vMmciFBRyRFe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661635879682,"user_tz":-120,"elapsed":27599,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"a59bd9ea-2ca6-460a-f311-38939caa11b5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 8.6 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 10.0 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 9.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 57.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.9-py3-none-any.whl (259 kB)\n","\u001b[K     |████████████████████████████████| 259 kB 9.6 MB/s \n","\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.12.1+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.4.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 6.8 MB/s \n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 74.9 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 66.3 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 74.6 MB/s \n","\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AtS4CD_krp3d","executionInfo":{"status":"ok","timestamp":1661635886480,"user_tz":-120,"elapsed":6803,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"outputs":[],"source":["import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch\n","from transformers import AutoModel\n","import torch.nn.functional as F\n","from sklearn.metrics import f1_score, accuracy_score, classification_report\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","# Any results you write to the current directory are saved as output.\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","from transformers import BertTokenizer,BertModel\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,Dataset\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from torch.optim import AdamW\n","from tqdm import tqdm\n","from argparse import ArgumentParser\n","from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n","from ignite.metrics import Accuracy, Loss\n","from ignite.engine.engine import Engine, State, Events\n","from ignite.handlers import EarlyStopping\n","from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n","from ignite.utils import convert_tensor\n","from torch.optim.lr_scheduler import ExponentialLR\n","import warnings  \n","warnings.filterwarnings('ignore')\n","import gc\n","import copy\n","import time\n","import random\n","import string\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Pytorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Utils\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, KFold\n","from transformers import AutoTokenizer, AutoModel, AdamW\n","import random\n","import os\n","from urllib import request\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n","\n","from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n","from transformers.data.processors import SingleSentenceClassificationProcessor\n","from transformers import Trainer , TrainingArguments\n","from transformers.trainer_utils import EvaluationStrategy\n","from transformers.data.processors.utils import InputFeatures\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"ARjNBDtgwfVJ"}},{"cell_type":"code","source":["class TrainDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = max_length\n","        self.tokenizer = tokenizer\n","        self.text = df['#2_content'].values\n","        self.label=df['#3_label'].values\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        # summary = self.summary[index]\n","        inputs_text = self.tokenizer.encode_plus(\n","                                text,\n","                                truncation=True,\n","                                add_special_tokens=True,\n","                                max_length=self.max_len,\n","                                padding='max_length'\n","                            )\n","        \n","                            \n","        target = self.label[index]\n","        \n","        text_ids = inputs_text['input_ids']\n","        text_mask = inputs_text['attention_mask']\n","        \n","       \n","        \n","        \n","        return {\n","            \n","            'text_ids': torch.tensor(text_ids, dtype=torch.long),\n","            'text_mask': torch.tensor(text_mask, dtype=torch.long),\n","            'target': torch.tensor(target, dtype=torch.float)\n","        }"],"metadata":{"id":"lLRNRjusoELI","executionInfo":{"status":"ok","timestamp":1661635886480,"user_tz":-120,"elapsed":12,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","# from sklearn.model_selection import train_test_split\n","# from torch.utils.data import Dataset, DataLoader\n","# import Dataset\n","# import os\n","# import numpy as np\n","# from emoji import UNICODE_EMOJI\n","# import TweetNormalizer\n","# import re\n","# import text_normalization\n","\n","\n","# dic = {\n","#       \"egypt\": 'المصرية',\n","# \t  \"nile\": 'المصرية',\n","# \t  \"msa\": \"اللغة العربية الفصحى\",\n","# \t  \"magreb\": \"المغربية\",\n","# \t  \"gulf\": \"الخليجية\",\n","# \t  \"levant\": \"الشامية\"\n","# }\n","\n","# def is_emoji(s):\n","#     return s in UNICODE_EMOJI\n","\n","# # add space near your emoji\n","# def add_space(text):\n","#     return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n","\n","# def preprocess(text, lang='ar'):\n","#     if lang == 'ar':\n","#         sent = add_space(text)\n","#         sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n","#         sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n","#         sent = sent.replace('_', ' ')\n","#         sent = sent.replace('#', ' ')\n","#     else:\n","#         sent = add_space(text)\n","#         sent = re.sub(r'(?:@[\\w_]+)', \"@user\", sent)\n","#         sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"http\", sent)\n","#         sent = sent.replace('_', ' ')\n","#         sent = sent.replace('#', ' ')\n","\n","#     return sent\n","\n","# def prepare_text(df, col='tweet'):\n","#     if col == 'tweet':\n","#         df['dialect'] = df['dialect'].map(dic)   \n","#     for i in range(df.shape[0]):\n","#         df.loc[i, col] = df.loc[i, 'dialect'] + ' [SEP] ' + df.loc[i, col]\n","\n","\n","#     return df\n","\n","# def augment_data(df_train,text_col,label_col):\n","#     df_aug = pd.DataFrame(columns=[text_col, label_col)\n","#     dic_dup = {1: 3,\n","#                0: 1\n","#                }\n","#     for i in range(df_train.shape[0]):\n","#         current = df_train.iloc[i]\n","#         text = current[text_col]\n","#         label_cat = current[label_col]\n","\n","#         aug_ratio = dic_dup[label_cat]\n","#         for k in range(aug_ratio):\n","#             tokens = text.split(' ')\n","#             l = len(tokens)\n","#             n = int(0.1 * l)\n","#             indices = np.random.choice(l, n, replace=False)\n","#             for j in range(len(indices)):\n","#                 tokens[indices[j]] = '[MASK]'\n","#             new_text = ' '.join(tokens)\n","#             entry = {text_col: new_text, label_col: label_cat}\n","#             df_aug = df_aug.append(entry, ignore_index=True)\n","#     df_aug.drop_duplicates(subset=[text_col], keep='first', inplace=True)\n","#     df = pd.concat([df_train,df_aug])\n","#     return df\n"],"metadata":{"id":"0ZOanFa2wz3L","executionInfo":{"status":"ok","timestamp":1661635886481,"user_tz":-120,"elapsed":11,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# '''\n","# Created by: Mohamed Salem Elhady  \n","# Email: mohamed.elaraby@alumni.ubc.ca\n","# Text Normalization: V1 \n","# '''\n","# import sys\n","# import re\n","# import emojis\n","# from emoji import UNICODE_EMOJI\n","# #sys.setdefaultencoding('utf-8')\n","# ##########################Clean Text Data #######################################\n","# ########################Global Variable Declaration##############################\n","# list_seeds = ['سبحان الله', 'الله أكبر', 'اللهم', 'بسم الله', 'يا رب', 'العضيم', 'سبحان', 'يارب', 'قران', 'quran',\n","#               'حديث', 'hadith', 'صلاه_الفجر', '﴾', 'ﷺ', 'صحيح البخاري', 'صحيح مسلم', 'يآرب', 'سورة']\n","# MaxWordPerTweet=7\n","# #################################################################################\n","# def is_emoji(s):\n","#     return s in UNICODE_EMOJI\n","\n","# # add space near your emoji\n","# def add_space(text):\n","#     return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n","\n","# def clean(sent):\n","#     \"\"\"clean data from any English char, emoticons, underscore, and repeated > 2\n","#     str -> str\"\"\"\n","#     p1 = re.compile('\\W')\n","#     p2 = re.compile('\\s+')\n","#     sent = re.sub(r\"http\\S+\", \"\", sent)\n","#     sent = ReplaceThreeOrMore(sent)\n","#     sent = remove_unicode_diac(sent)\n","#     sent = sent.replace('_', ' ')\n","#     sent = re.sub(r'[A-Za-z0-9]', r'', sent)\n","#     sent = re.sub(p1, ' ', sent)\n","#     sent = re.sub(p2, ' ', sent)\n","#     return sent\n","\n","# def tokenize_emojis(tweet):\n","#     return list(emojis.get(tweet))\n","\n","# def replace_emoji(sent):\n","#     emoji_pattern = re.compile(\"[\"\n","#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","#                                \"]+\", flags=re.UNICODE)\n","#     return emoji_pattern.sub(r'[MASK]', sent)\n","\n","# def preprocess(tweet):\n","#     tweet = add_space(tweet)\n","#     emos = tokenize_emojis(tweet)\n","#     sent = remove_unicode_diac(tweet)\n","#     sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n","#     sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n","#     sent = sent.replace('_', ' ')\n","#     sent = sent.replace('#', ' ')\n","#     if len(emos) > 0:\n","#         sent = sent + ' [SEP] '  + ' '.join(emos)\n","#     #    #sent = sent + ' [SEP] ' + clean_unicode(tweet) + ' [SEP] ' + ' '.join(emos)\n","\n","#     #else:\n","#     #    sent = sent + ' [SEP] ' + clean_unicode(tweet)\n","#     return sent\n","\n","# def preprocess_last(tweet, k=0):\n","#     emos = tokenize_emojis(tweet)\n","#     sent = remove_unicode_diac(tweet)\n","#     sent = re.sub(r'(?:@[\\w_]+)', \"\", sent)\n","#     sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"\", sent)\n","#     sent = sent.replace('_', ' ')\n","#     sent = sent.replace('#', ' ')\n","#     if k == 0:\n","#         sent = sent\n","#     elif k ==1 :\n","#         sent = sent + ' [SEP] ' + ' '.join(emos)\n","#     elif k==2 :\n","#         sent = sent + ' [SEP] ' + clean_unicode(tweet) + ' [SEP] ' + ' '.join(emos)\n","#     elif k == 3:\n","#         sent = sent + ' [SEP] ' + clean_unicode(tweet)\n","#     else:\n","#         sent = replace_emoji(sent)\n","#         sent = sent + ' [SEP] ' + clean_unicode(tweet) + ' [SEP] ' + ' '.join(emos)\n","\n","#     return sent\n","\n","\n","# def normalize(sent):\n","#     \"\"\"clean data from any English char, emoticons, underscore, and repeated > 2\n","#     str -> str\"\"\"\n","#     sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n","#     sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n","#     #sent = re.sub(r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", \"hashtag\", sent)\n","#     sent = ReplaceThreeOrMore(sent)\n","#     sent = remove_unicode_diac(sent)\n","#     sent = sent.replace('_', ' ')\n","#     return sent\n","\n","# def ReplaceThreeOrMore(s):\n","#     # pattern to look for three or more repetitions of any character, including\n","#     # newlines.\n","#     pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n","#     return pattern.sub(r\"\\1\\1\", s)\n","# def norm_alif(text):\n","#     text = text.replace(u\"\\u0625\", u\"\\u0627\")  # HAMZA below, with LETTER ALEF\n","#     #text = text.replace(u\"\\u0621\", u\"\\u0627\")  # HAMZA, with LETTER ALEF\n","#     text = text.replace(u\"\\u0622\", u\"\\u0627\")  # ALEF WITH MADDA ABOVE, with LETTER ALEF\n","#     text = text.replace(u\"\\u0623\", u\"\\u0627\")  # ALEF WITH HAMZA ABOVE, with LETTER ALEF\n","#     return text\n","# def remove_unicode_diac(text):\n","#     \"\"\"Takes Arabic in utf-8 and returns same text without diac\"\"\"\n","#     # Replace diacritics with nothing\n","#     text = text.replace(u\"\\u064B\", \"\")  # fatHatayn\n","#     text = text.replace(u\"\\u064C\", \"\")  # Dammatayn\n","#     text = text.replace(u\"\\u064D\", \"\")  # kasratayn\n","#     text = text.replace(u\"\\u064E\", \"\")  # fatHa\n","#     text = text.replace(u\"\\u064F\", \"\")  # Damma\n","#     text = text.replace(u\"\\u0650\", \"\")  # kasra\n","#     text = text.replace(u\"\\u0651\", \"\")  # shaddah\n","#     text = text.replace(u\"\\u0652\", \"\")  # sukuun\n","#     text = text.replace(u\"\\u0670\", \"`\")  # dagger 'alif\n","#     return text\n","# def norm_taa(text):\n","#     text=text.replace(u\"\\u0629\", u\"\\u0647\") # taa' marbuuTa, with haa'\n","#     #text=text.replace(u\"\\u064A\", u\"\\u0649\") # yaa' with 'alif maqSuura\n","#     return text\n","# def norm_yaa(text):\n","#     if len(text)!=0:\n","#         if text[-1] == u\"\\u064A\":\n","#             text = text[:-1] + text[-1].replace(u\"\\u064A\", u\"\\u0649\")  # yaa' with 'alif maqSuura\n","#     return text\n","\n","# def NormForWord2Vec(text):\n","#     text=norm_taa(text)\n","#     text=norm_yaa(text)\n","#     text=norm_alif(text)\n","#     return text\n","\n","# def remove_nonunicode2(Tweet):\n","#     ## defining set of unicode ##\n","#     #u\"\"\n","#     #Tweet=Tweet.decode(\"utf-8\")\n","#     UniLex={ ## This is list of all arabic unicode characters in addition to space (to separate words)\n","#             u\"\\u0622\",\n","#             u\"\\u0626\",\n","#             u\"\\u0628\",\n","#             u\"\\u062a\",\n","#             u\"\\u062c\",\n","#             u\"\\u06af\",\n","#             u\"\\u062e\",\n","#             u\"\\u0630\",\n","#             u\"\\u0632\",\n","#             u\"\\u0634\",\n","#             u\"\\u0636\",\n","#             u\"\\u0638\",\n","#             u\"\\u063a\",\n","#             u\"\\u0640\",\n","#             u\"\\u0642\",\n","#             u\"\\u0644\",\n","#             u\"\\u0646\",\n","#             u\"\\u0648\",\n","#             u\"\\u064a\",\n","#             u\"\\u0670\",\n","#             u\"\\u067e\",\n","#             u\"\\u0686\",\n","#             u\"\\u0621\",\n","#             u\"\\u0623\",\n","#             u\"\\u0625\",\n","#             u\"\\u06a4\",\n","#             u\"\\u0627\",\n","#             u\"\\u0629\",\n","#             u\"\\u062b\",\n","#             u\"\\u062d\",\n","#             u\"\\u062f\",\n","#             u\"\\u0631\",\n","#             u\"\\u0633\",\n","#             u\"\\u0635\",\n","#             u\"\\u0637\",\n","#             u\"\\u0639\",\n","#             u\"\\u0641\",\n","#             u\"\\u0643\",\n","#             u\"\\u0645\",\n","#             u\"\\u0647\",\n","#             u\"\\u0649\",\n","#             u\"\\u0671\",\n","#             ' ',\n","#             '\\n'\n","#           }\n","#     fin_tweet=\"\"\n","#     for c in Tweet:\n","#         if c in UniLex:\n","#            fin_tweet=fin_tweet+c\n","#     return fin_tweet\n","\n","# ###### Heuristics Calculations ######\n","# def diac_counter(text):\n","#     #text=text.decode(\"utf-8\")\n","#     diac = [u\"\\u064B\",u\"\\u064C\", u\"\\u064D\", u\"\\u064E\", u\"\\u064F\", u\"\\u0650\", u\"\\u0651\", u\"\\u0652\", u\"\\u0670\"]\n","#     diac_count=0\n","#     for d in diac:\n","#         diac_count+=text.count(d)\n","# #         if d in text:\n","# #             print(d)\n","# #             diac_count+=1\n","#     return diac_count\n","# def check_seed(list_seeds, text):\n","#     \"\"\n","#     for word in list_seeds:\n","#         text = text.lower()\n","#         if word.decode(\"utf-8\") in text:\n","#             return True\n","#     return False\n","# def EnglishCount(text):\n","#     printable = ['e', 'a', 'o', 't', 'i']\n","#     count = 0\n","#     for ch in printable:\n","#         count += text.count(ch.lower())\n","#     return count\n","# ########################################\n","\n","\n","\n","# def eliminate_single_char_words(Tweet):\n","#     parts = Tweet.split(\" \")\n","#     cleaned_line_parts = []\n","#     for P in parts:\n","#         if len(P) != 1:\n","#             cleaned_line_parts.append(P)\n","#     cleaned_line = ' '.join(cleaned_line_parts)\n","#     return cleaned_line\n","# def clean_unicode(Tweet):\n","#     tweet=normalize(Tweet.strip(\"\\n\"))\n","#     if len(tweet) !=0:\n","#         sentence = []\n","#         for word in tweet.split(\" \"):\n","#             word = remove_unicode_diac(word)\n","#             word = norm_alif(word)\n","#             word = norm_taa(word)\n","#             word = norm_yaa(word)\n","#             word = normalize(word)\n","#             sentence.append(word)\n","#         tweet = ' '.join(sentence)\n","#         tweet =remove_nonunicode2(tweet)\n","#         tweet =eliminate_single_char_words(tweet)\n","#     return tweet\n","\n","# def clean_unicode2(Tweet):\n","#     KeepUniOnly(Tweet)\n","#     tweet=normalize(Tweet.strip(\"\\n\"))\n","#     if len(tweet) !=0:\n","#         sentence = []\n","#         for word in tweet.split(\" \"):\n","#             word = remove_unicode_diac(word)\n","#             word = normalize(word)\n","#             sentence.append(word)\n","#         tweet = ' '.join(sentence)\n","#         tweet =remove_nonunicode2(tweet)\n","#         tweet =eliminate_single_char_words(tweet)\n","#     return tweet\n","\n","# def NormCorpusFinal(Tweet):\n","#     tweet=KeepUniOnly(Tweet)\n","#     tweet=NormForWord2Vec(tweet)\n","#     return tweet\n","\n","# def KeepUniOnly(Tweet):## this one is without normalization\n","#     tweet=Tweet.replace(\"# \",\" \")\n","#     tweet=tweet.replace(\"#\",\" \")\n","#     tweet=tweet.replace(\"_\",\" \")\n","#     tweet=tweet.replace(u\"\\u0657\",\" \")\n","#     tweet=tweet.replace(\"\\n\",\" \")\n","#     tweet=remove_nonunicode2(tweet)\n","#     tweet=eliminate_single_char_words(tweet)\n","#     tweet=ReplaceThreeOrMore(tweet)\n","#     return tweet\n","\n","# def get_charset(rawtext):\n","#     chars = sorted(list(set(rawtext)))\n","#     return chars\n","\n","# def DialectChecker(text):\n","#     ##Based on Hueristics done by Hassan\n","#     if (diac_counter(text)>5 or check_seed(list_seeds,text) or EnglishCount(text)>4 or \"<URL>\"  in text\n","#         or text.count('#') >2 or '\"'  in text or text.count('@') or \"\\\"RT\" in text or len(text.split(\" \")) <7):\n","#         return False\n","#     else:\n","#         return True\n","\n","# ###############################################################\n","# '''\n","# Fread=open(\"Egypt_portion.txt\",'r')\n","# Fwriter=open(\"Egypt_portion_norm.txt\",'w')\n","# for line in Fread:\n","#     cleaned_line=clean_unicode_for_w2v(line)\n","#     Fwriter.write(str(cleaned_line))\n","# Fwriter.close()\n","# '''"],"metadata":{"id":"QcOa9agTwhIg","executionInfo":{"status":"ok","timestamp":1661635886481,"user_tz":-120,"elapsed":10,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Losses"],"metadata":{"id":"iVcFbe1Bvcqh"}},{"cell_type":"code","source":["class F1_Loss(nn.Module):\n","    '''Calculate F1 score. Can work with gpu tensors\n","    \n","    The original implmentation is written by Michal Haltuf on Kaggle.\n","    \n","    Returns\n","    -------\n","    torch.Tensor\n","        `ndim` == 1. epsilon <= val <= 1\n","    \n","    Reference\n","    ---------\n","    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n","    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n","    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n","    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n","    '''\n","    def __init__(self, epsilon=1e-7):\n","        super().__init__()\n","        self.epsilon = epsilon\n","        \n","    def forward(self, y_pred, y_true,):\n","        # assert y_pred.ndim == 2\n","        # assert y_true.ndim == 1\n","        # print(y_pred.shape)\n","        # print(y_true.shape)\n","        # y_pred[y_pred<0.5]=0\n","        # y_pred[y_pred>=0.5]=0\n","\n","\n","        \n","        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 18).to(torch.float32)\n","        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n","        \n","        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n","        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n","        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n","        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n","        f1=f1.detach()\n","        # print(f1.shape)\n","        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n","        # y_true=y_true.reshape((y_true.shape[0], 1))\n","\n","        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n","        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n","\n","\n","        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n","        # print(y_pred)\n","        # print(y_true_one_hot)\n","        CE =torch.nn.CrossEntropyLoss(weight=( 1 - f1))(y_pred, y_true_one_hot)\n","        # loss = ( 1 - f1)  * CE\n","        return  CE.mean()"],"metadata":{"id":"RGw6mbs0uIlN","executionInfo":{"status":"ok","timestamp":1661635886481,"user_tz":-120,"elapsed":9,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class Recall_Loss(nn.Module):\n","    '''Calculate Recall score. Can work with gpu tensors\n","    \n","    The original implmentation is written by Michal Haltuf on Kaggle.\n","    \n","    Returns\n","    -------\n","    torch.Tensor\n","        `ndim` == 1. epsilon <= val <= 1\n","    \n","    Reference\n","    ---------\n","    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n","    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n","    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n","    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n","    '''\n","    def __init__(self, epsilon=1e-7):\n","        super().__init__()\n","        self.epsilon = epsilon\n","        \n","    def forward(self, y_pred, y_true,):\n","        # assert y_pred.ndim == 2\n","        # assert y_true.ndim == 1\n","        # print(y_pred.shape)\n","        # print(y_true.shape)\n","        # y_pred[y_pred<0.5]=0\n","        # y_pred[y_pred>=0.5]=0\n","\n","\n","        \n","        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 18).to(torch.float32)\n","        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n","        \n","        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n","        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n","        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        # f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n","        # f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n","        # f1=f1.detach()\n","        # print(f1.shape)\n","        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n","        # y_true=y_true.reshape((y_true.shape[0], 1))\n","\n","        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n","        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n","\n","\n","        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n","        # print(y_pred)\n","        # print(y_true_one_hot)\n","        recall=recall.detach()\n","        CE =torch.nn.CrossEntropyLoss(weight=( 1 - recall))(y_pred, y_true_one_hot)\n","        # loss = ( 1 - f1)  * CE\n","        return  CE.mean()"],"metadata":{"id":"Pdd02bGivpr5","executionInfo":{"status":"ok","timestamp":1661635886482,"user_tz":-120,"elapsed":9,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["## Based on https://github.com/AbdelkaderMH/iSarcasmEval/blob/8f28f24ebfb641415a604329ed859506ae687148/focal_loss.py\n","class BinaryFocalLoss(nn.Module):\n","    \"\"\"\n","    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n","    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n","        Focal_Loss= -1*alpha*(1-pt)*log(pt)\n","    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n","    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n","                    focus on hard misclassified example\n","    :param reduction: `none`|`mean`|`sum`\n","    :param **kwargs\n","        balance_index: (int) balance class index, should be specific when alpha is float\n","    \"\"\"\n","\n","    def __init__(self, alpha=3, gamma=2, ignore_index=None, reduction='mean', **kwargs):\n","        super(BinaryFocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.smooth = 1e-6  # set '1e-4' when train with FP16\n","        self.ignore_index = ignore_index\n","        self.reduction = reduction\n","\n","        assert self.reduction in ['none', 'mean', 'sum']\n","\n","        # if self.alpha is None:\n","        #     self.alpha = torch.ones(2)\n","        # elif isinstance(self.alpha, (list, np.ndarray)):\n","        #     self.alpha = np.asarray(self.alpha)\n","        #     self.alpha = np.reshape(self.alpha, (2))\n","        #     assert self.alpha.shape[0] == 2, \\\n","        #         'the `alpha` shape is not match the number of class'\n","        # elif isinstance(self.alpha, (float, int)):\n","        #     self.alpha = np.asarray([self.alpha, 1.0 - self.alpha], dtype=np.float).view(2)\n","\n","        # else:\n","        #     raise TypeError('{} not supported'.format(type(self.alpha)))\n","\n","    def forward(self, output, target):\n","        prob = torch.sigmoid(output)\n","        prob = torch.clamp(prob, self.smooth, 1.0 - self.smooth)\n","\n","        valid_mask = None\n","        if self.ignore_index is not None:\n","            valid_mask = (target != self.ignore_index).float()\n","\n","        pos_mask = (target == 1).float()\n","        neg_mask = (target == 0).float()\n","        if valid_mask is not None:\n","            pos_mask = pos_mask * valid_mask\n","            neg_mask = neg_mask * valid_mask\n","\n","        pos_weight = (pos_mask * torch.pow(1 - prob, self.gamma)).detach()\n","        pos_loss = -pos_weight * torch.log(prob)  # / (torch.sum(pos_weight) + 1e-4)\n","\n","        neg_weight = (neg_mask * torch.pow(prob, self.gamma)).detach()\n","        neg_loss = -self.alpha * neg_weight * F.logsigmoid(-output)  # / (torch.sum(neg_weight) + 1e-4)\n","        loss = pos_loss + neg_loss\n","        loss = loss.mean()\n","        return loss\n","\n","\n","class FocalLoss_Ori(nn.Module):\n","    \"\"\"\n","    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n","    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n","    Focal_Loss= -1*alpha*((1-pt)**gamma)*log(pt)\n","    Args:\n","        num_class: number of classes\n","        alpha: class balance factor\n","        gamma:\n","        ignore_index:\n","        reduction:\n","    \"\"\"\n","\n","    def __init__(self, num_class, alpha=None, gamma=2, ignore_index=None, reduction='mean'):\n","        super(FocalLoss_Ori, self).__init__()\n","        self.num_class = num_class\n","        self.gamma = gamma\n","        self.reduction = reduction\n","        self.smooth = 1e-4\n","        self.ignore_index = ignore_index\n","        self.alpha = alpha\n","        if alpha is None:\n","            self.alpha = torch.ones(num_class, )\n","        elif isinstance(alpha, (int, float)):\n","            self.alpha = torch.as_tensor([alpha] * num_class)\n","        elif isinstance(alpha, (list, np.ndarray)):\n","            self.alpha = torch.as_tensor(alpha)\n","        if self.alpha.shape[0] != num_class:\n","            raise RuntimeError('the length not equal to number of class')\n","\n","        # if isinstance(self.alpha, (list, tuple, np.ndarray)):\n","        #     assert len(self.alpha) == self.num_class\n","        #     self.alpha = torch.Tensor(list(self.alpha))\n","        # elif isinstance(self.alpha, (float, int)):\n","        #     assert 0 < self.alpha < 1.0, 'alpha should be in `(0,1)`)'\n","        #     assert balance_index > -1\n","        #     alpha = torch.ones((self.num_class))\n","        #     alpha *= 1 - self.alpha\n","        #     alpha[balance_index] = self.alpha\n","        #     self.alpha = alpha\n","        # elif isinstance(self.alpha, torch.Tensor):\n","        #     self.alpha = self.alpha\n","        # else:\n","        #     raise TypeError('Not support alpha type, expect `int|float|list|tuple|torch.Tensor`')\n","\n","    def forward(self, logit, target):\n","        # assert isinstance(self.alpha,torch.Tensor)\\\n","        N, C = logit.shape[:2]\n","        alpha = self.alpha.to(logit.device)\n","        prob = F.softmax(logit, dim=1)\n","        if prob.dim() > 2:\n","            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n","            prob = prob.view(N, C, -1)\n","            prob = prob.transpose(1, 2).contiguous()  # [N,C,d1*d2..] -> [N,d1*d2..,C]\n","            prob = prob.view(-1, prob.size(-1))  # [N,d1*d2..,C]-> [N*d1*d2..,C]\n","        ori_shp = target.shape\n","        target = target.view(-1, 1)  # [N,d1,d2,...]->[N*d1*d2*...,1]\n","        valid_mask = None\n","        if self.ignore_index is not None:\n","            valid_mask = target != self.ignore_index\n","            target = target * valid_mask\n","\n","        # ----------memory saving way--------\n","        prob = prob.gather(1, target).view(-1) + self.smooth  # avoid nan\n","        logpt = torch.log(prob)\n","        # alpha_class = alpha.gather(0, target.view(-1))\n","        alpha_class = alpha[target.squeeze().long()]\n","        class_weight = -alpha_class * torch.pow(torch.sub(1.0, prob), self.gamma)\n","        loss = class_weight * logpt\n","        if valid_mask is not None:\n","            loss = loss * valid_mask.squeeze()\n","\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","            if valid_mask is not None:\n","                loss = loss.sum() / valid_mask.sum()\n","        elif self.reduction == 'none':\n","            loss = loss.view(ori_shp)\n","        return loss\n","\n","\n","\n","def weighted_binary_cross_entropy(input, targets, pos_weight, weight=None, size_average=True, reduce=True):\n","    \"\"\"\n","    Args:\n","        sigmoid_x: predicted probability of size [N,C], N sample and C Class. Eg. Must be in range of [0,1], i.e. Output from Sigmoid.\n","        targets: true value, one-hot-like vector of size [N,C]\n","        pos_weight: Weight for postive sample\n","    \"\"\"\n","    sigmoid_x = torch.sigmoid(input)\n","    if not (targets.size() == sigmoid_x.size()):\n","        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(targets.size(), sigmoid_x.size()))\n","\n","    loss = -pos_weight* targets * sigmoid_x.log() - (1-targets)*(1-sigmoid_x).log()\n","\n","    if weight is not None:\n","        loss = loss * weight\n","\n","    if not reduce:\n","        return loss\n","    elif size_average:\n","        return loss.mean()\n","    else:\n","        return loss.sum()\n","\n","class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight= 1, weight=None, PosWeightIsDynamic= True, WeightIsDynamic= False, size_average=True, reduce=True):\n","        \"\"\"\n","        Args:\n","            pos_weight = Weight for postive samples. Size [1,C]\n","            weight = Weight for Each class. Size [1,C]\n","            PosWeightIsDynamic: If True, the pos_weight is computed on each batch. If pos_weight is None, then it remains None.\n","            WeightIsDynamic: If True, the weight is computed on each batch. If weight is None, then it remains None.\n","        \"\"\"\n","        super().__init__()\n","\n","        #self.register_buffer('weight', weight)\n","        #self.register_buffer('pos_weight', pos_weight)\n","        self.size_average = size_average\n","        self.reduce = reduce\n","        self.PosWeightIsDynamic = PosWeightIsDynamic\n","\n","    def forward(self, input, target):\n","        # pos_weight = Variable(self.pos_weight) if not isinstance(self.pos_weight, Variable) else self.pos_weight\n","        if self.PosWeightIsDynamic:\n","            positive_counts = target.sum(dim=0)\n","            nBatch = len(target)\n","            self.pos_weight = (nBatch - positive_counts)/(positive_counts +1e-5)\n","\n","\n","        return weighted_binary_cross_entropy(input, target,\n","                                                self.pos_weight,\n","                                                weight=None,\n","                                                size_average=self.size_average,\n","                                                reduce=self.reduce)\n","\n","\n","class WeightedCELoss(nn.Module):\n","    def __init__(self, size_average=True, reduce=True):\n","        \"\"\"\n","        Args:\n","            pos_weight = Weight for postive samples. Size [1,C]\n","            weight = Weight for Each class. Size [1,C]\n","            PosWeightIsDynamic: If True, the pos_weight is computed on each batch. If pos_weight is None, then it remains None.\n","            WeightIsDynamic: If True, the weight is computed on each batch. If weight is None, then it remains None.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.size_average = size_average\n","        self.reduce = reduce\n","\n","    def forward(self, input, target):\n","        positive_counts = target.sum(dim=0)\n","        nBatch = len(target)\n","        pos_weight = (nBatch - positive_counts)/(positive_counts +1e-5)\n","        neg_count = nBatch - positive_counts\n","        neg_weight = (nBatch - neg_count)/(neg_count +1e-5)\n","\n","        weight = torch.tensor([neg_weight, pos_weight], device=target.device)\n","  \n","\n","\n","        return F.cross_entropy(input, target, weight=weight)\n","\n","\n","\n","class FLMultiLoss(nn.Module):\n","    def __init__(self, gamma= 2):\n","        \"\"\"\n","        Args:\n","            pos_weight = Weight for postive samples. Size [1,C]\n","            weight = Weight for Each class. Size [1,C]\n","            PosWeightIsDynamic: If True, the pos_weight is computed on each batch. If pos_weight is None, then it remains None.\n","            WeightIsDynamic: If True, the weight is computed on each batch. If weight is None, then it remains None.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.gamma = gamma\n","    def forward(self, input, target):\n","\n","\n","        return focal_binary_cross_entropy(input, target, gamma=2)\n","\n","def EntropyLoss(input_):\n","    mask = input_.ge(0.000001)\n","    mask_out = torch.masked_select(input_, mask)\n","    entropy = -(torch.sum(mask_out * torch.log(mask_out)))\n","    return entropy / float(input_.size(0))\n","\n","def focal_binary_cross_entropy(logits, targets, gamma=2):\n","    num_label = targets.shape[1]\n","    l = logits.reshape(-1)\n","    t = targets.reshape(-1)\n","    p = torch.sigmoid(l)\n","    p = torch.where(t >= 0.5, p, 1-p)\n","    logp = - torch.log(torch.clamp(p, 1e-4, 1-1e-4))\n","    loss = logp*((1-p)**gamma)\n","    loss = num_label*loss.mean()\n","    return loss"],"metadata":{"id":"zKy23cw1wHB9","executionInfo":{"status":"ok","timestamp":1661635886886,"user_tz":-120,"elapsed":412,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from typing import Optional, Sequence\n","\n","import torch\n","from torch import Tensor\n","from torch import nn\n","from torch.nn import functional as F\n","\n","\n","class FocalLoss(nn.Module):\n","    \"\"\" Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n","    It is essentially an enhancement to cross entropy loss and is\n","    useful for classification tasks when there is a large class imbalance.\n","    x is expected to contain raw, unnormalized scores for each class.\n","    y is expected to contain class labels.\n","    Shape:\n","        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n","        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 alpha: Optional[Tensor] = None,\n","                 gamma: float = 0.,\n","                 reduction: str = 'mean',\n","                 ignore_index: int = -100):\n","        \"\"\"Constructor.\n","        Args:\n","            alpha (Tensor, optional): Weights for each class. Defaults to None.\n","            gamma (float, optional): A constant, as described in the paper.\n","                Defaults to 0.\n","            reduction (str, optional): 'mean', 'sum' or 'none'.\n","                Defaults to 'mean'.\n","            ignore_index (int, optional): class label to ignore.\n","                Defaults to -100.\n","        \"\"\"\n","        if reduction not in ('mean', 'sum', 'none'):\n","            raise ValueError(\n","                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n","\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.ignore_index = ignore_index\n","        self.reduction = reduction\n","\n","        self.nll_loss = nn.NLLLoss(\n","            weight=alpha, reduction='none', ignore_index=ignore_index)\n","\n","    def __repr__(self):\n","        arg_keys = ['alpha', 'gamma', 'ignore_index', 'reduction']\n","        arg_vals = [self.__dict__[k] for k in arg_keys]\n","        arg_strs = [f'{k}={v}' for k, v in zip(arg_keys, arg_vals)]\n","        arg_str = ', '.join(arg_strs)\n","        return f'{type(self).__name__}({arg_str})'\n","\n","    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n","        if x.ndim > 2:\n","            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n","            c = x.shape[1]\n","            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n","            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n","            y = y.view(-1)\n","\n","        unignored_mask = y != self.ignore_index\n","        y = y[unignored_mask]\n","        if len(y) == 0:\n","            return torch.tensor(0.)\n","        x = x[unignored_mask]\n","\n","        # compute weighted cross entropy term: -alpha * log(pt)\n","        # (alpha is already part of self.nll_loss)\n","        log_p = F.log_softmax(x, dim=-1)\n","        ce = self.nll_loss(log_p, y)\n","\n","        # get true class column from each row\n","        all_rows = torch.arange(len(x))\n","        log_pt = log_p[all_rows, y]\n","\n","        # compute focal term: (1 - pt)^gamma\n","        pt = log_pt.exp()\n","        focal_term = (1 - pt)**self.gamma\n","\n","        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n","        loss = focal_term * ce\n","\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","\n","        return loss\n","\n","\n","def focal_loss(alpha: Optional[Sequence] = None,\n","               gamma: float = 0.,\n","               reduction: str = 'mean',\n","               ignore_index: int = -100,\n","               device='cuda',\n","               dtype=torch.float32) -> FocalLoss:\n","    \"\"\"Factory function for FocalLoss.\n","    Args:\n","        alpha (Sequence, optional): Weights for each class. Will be converted\n","            to a Tensor if not None. Defaults to None.\n","        gamma (float, optional): A constant, as described in the paper.\n","            Defaults to 0.\n","        reduction (str, optional): 'mean', 'sum' or 'none'.\n","            Defaults to 'mean'.\n","        ignore_index (int, optional): class label to ignore.\n","            Defaults to -100.\n","        device (str, optional): Device to move alpha to. Defaults to 'cpu'.\n","        dtype (torch.dtype, optional): dtype to cast alpha to.\n","            Defaults to torch.float32.\n","    Returns:\n","        A FocalLoss object\n","    \"\"\"\n","    if alpha is not None:\n","        if not isinstance(alpha, Tensor):\n","            alpha = torch.tensor(alpha)\n","        alpha = alpha.to(device=device, dtype=dtype)\n","\n","    fl = FocalLoss(\n","        alpha=alpha,\n","        gamma=gamma,\n","        reduction=reduction,\n","        ignore_index=ignore_index)\n","    return fl"],"metadata":{"id":"dG5x6Ck0nOh_","executionInfo":{"status":"ok","timestamp":1661635886886,"user_tz":-120,"elapsed":15,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"fvByMHwKuI4d"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","from transformers import AutoModel\n","import torch.nn.functional as F\n","\n","def init_weights(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv2d') != -1 or classname.find('ConvTranspose2d') != -1:\n","        nn.init.kaiming_uniform_(m.weight)\n","        nn.init.zeros_(m.bias)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight, 1.0, 0.02)\n","        nn.init.zeros_(m.bias)\n","    elif classname.find('Linear') != -1:\n","        nn.init.xavier_normal_(m.weight)\n","        if m.bias is not None:\n","            nn.init.zeros_(m.bias)\n","\n","\n","class AttentionWithContext(nn.Module):\n","    def __init__(self, hidden_dim):\n","        super(AttentionWithContext, self).__init__()\n","\n","        self.attn = nn.Linear(hidden_dim, hidden_dim)\n","        self.contx = nn.Linear(hidden_dim, 1, bias=False)\n","        #self.apply(init_weights)\n","    def forward(self, inp):\n","        u = torch.tanh_(self.attn(inp))\n","        a = F.softmax(self.contx(u))\n","        s = (a * inp).sum(1)\n","        return s\n","\n","\n","class TransformerLayer(nn.Module):\n","    def __init__(self,\n","                 pretrained_path='aubmindlab/bert-base-arabert'):\n","        super(TransformerLayer, self).__init__()\n","\n","        \n","        self.transformer = AutoModel.from_pretrained(pretrained_path, output_hidden_states=True)\n","\n","\n","    def forward(self, input_ids=None, attention_mask=None):\n","        outputs = self.transformer(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","            , output_hidden_states=True\n","        )\n","        #(output_last_layer, pooled_cls, (output_layers))\n","        #output[0] (8, seqlen=64, 768) cls [8, 768] ( 12 (8, seqlen=64, 768))\n","\n","        return outputs\n","\n","    def output_num(self):\n","        return self.transformer.config.hidden_size\n","\n","class ATTClassifier(nn.Module):\n","    def __init__(self, in_feature, class_num=1, dropout_prob=0.2):\n","        super(ATTClassifier, self).__init__()\n","        self.attention = AttentionWithContext(in_feature)\n","\n","        self.Classifier = nn.Sequential(\n","            nn.Linear(2 * in_feature, 512),\n","            nn.Dropout(dropout_prob),\n","            nn.ReLU(),\n","            nn.Linear(512, class_num)\n","        )\n","\n","        self.apply(init_weights)\n","\n","    def forward(self, x):\n","        att = self.attention(x[0]) #(X[0] (bs, seqlenght, embedD) att = \\sum_i alpha_i x[0][i]\n","\n","        xx = torch.cat([att, x[1]], 1)\n","\n","        out = self.Classifier(xx)\n","        return out\n","class Attention(nn.Module):\n","    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","        \n","        self.supports_masking = True\n","\n","        self.bias = bias\n","        self.feature_dim = feature_dim\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        \n","        weight = torch.zeros(feature_dim, 1)\n","        nn.init.kaiming_uniform_(weight)\n","        self.weight = nn.Parameter(weight)\n","        \n","        if bias:\n","            self.b = nn.Parameter(torch.zeros(step_dim))\n","        \n","    def forward(self, x, mask=None):\n","        feature_dim = self.feature_dim \n","        step_dim = self.step_dim\n","\n","        eij = torch.mm(\n","            x.contiguous().view(-1, feature_dim), \n","            self.weight\n","        ).view(-1, step_dim)\n","        \n","        if self.bias:\n","            eij = eij + self.b\n","            \n","        eij = torch.tanh(eij)\n","        a = torch.exp(eij)\n","        \n","        if mask is not None:\n","            a = a * mask\n","\n","        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n","\n","        weighted_input = x * torch.unsqueeze(a, -1)\n","        return torch.sum(weighted_input, 1)\n","\n","class WeightedLayerPooling(nn.Module):\n","    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights=None):\n","        super(WeightedLayerPooling, self).__init__()\n","        self.layer_start = layer_start\n","        self.num_hidden_layers = num_hidden_layers\n","        self.layer_weights = layer_weights if layer_weights is not None \\\n","            else nn.Parameter(\n","            torch.tensor([1] * (num_hidden_layers + 1 - layer_start), dtype=torch.float)\n","        )\n","\n","    def forward(self, all_hidden_states):\n","        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n","        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n","        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n","        return weighted_average\n","class NADIModel(nn.Module):\n","  def __init__(self, pretrained_path='aubmindlab/bert-base-arabert',in_feature=768, class_num=18, dropout_prob=0.2):\n","        super(NADIModel, self).__init__()\n","        self.base_model=TransformerLayer(pretrained_path).to('cuda')\n","        self.config = AutoConfig.from_pretrained(pretrained_path)\n","        self.weighted_pooler = WeightedLayerPooling(num_hidden_layers=self.config.num_hidden_layers, layer_start=4)\n","        self.att=Attention(768, 512).to('cuda')\n","        self.classifier=nn.Linear(768, class_num)\n","  def forward(self, ids,mask):\n","    output=self.base_model(ids,mask)\n","    all_hidden_states = torch.stack(output.hidden_states)\n","    weighted_pooling_embeddings = (self.weighted_pooler(all_hidden_states)) # For WeightedLayerPooling\n","    # weighted_pooling_embeddings = weighted_pooling_embeddings[:, 0]\n","    # print(weighted_pooling_embeddings.shape)\n","    output=self.att(weighted_pooling_embeddings)\n","    output=self.classifier(output)\n","    # output=torch.softmax(output, dim=1)\n","    return output\n"," "],"metadata":{"id":"FW53GnvRuJ6J","executionInfo":{"status":"ok","timestamp":1661635886887,"user_tz":-120,"elapsed":14,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Train, Validation"],"metadata":{"id":"SYQWLGzVyqt_"}},{"cell_type":"code","source":["class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n","    \"\"\"\n","    Samples elements randomly from a given list of indices for imbalanced dataset\n","    Arguments:\n","        indices (list, optional): a list of indices\n","        num_samples (int, optional): number of samples to draw\n","    \"\"\"\n","\n","    def __init__(self, dataset, indices=None, num_samples=None):\n","        # if indices is not provided,\n","        # all elements in the dataset will be considered\n","        self.indices = list(range(len(dataset['#3_label']))) \\\n","            if indices is None else indices\n","\n","        # if num_samples is not provided,\n","        # draw `len(indices)` samples in each iteration\n","        self.num_samples = len(self.indices) \\\n","            if num_samples is None else num_samples\n","\n","        # distribution of classes in the dataset\n","        label_to_count = {}\n","        for idx in self.indices:\n","            label = self._get_label(dataset, idx)\n","            if label in label_to_count:\n","                label_to_count[label] += 1\n","            else:\n","                label_to_count[label] = 1\n","\n","        # weight for each sample\n","        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n","        self.weights = torch.DoubleTensor(weights)\n","\n","    def _get_label(self, dataset, id_):\n","        return dataset['#3_label'][id_]\n","\n","    def __iter__(self):\n","        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n","\n","    def __len__(self):\n","        return self.num_samples"],"metadata":{"id":"pjYrf5IerGh7","executionInfo":{"status":"ok","timestamp":1661635886888,"user_tz":-120,"elapsed":14,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def criterion(outputs1,  targets):\n","\n","    criterion = F1_Loss()\n","    criterion_2 = FocalLoss()\n","    loss = 0.5*criterion(outputs1, targets)+0.5*criterion_2(outputs1, targets)\n","    return loss"],"metadata":{"id":"ZWP3677hqMr1","executionInfo":{"status":"ok","timestamp":1661635886889,"user_tz":-120,"elapsed":14,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        \n","        text_ids = data['text_ids'].to(device, dtype = torch.long)\n","        text_mask = data['text_mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","        \n","        batch_size = text_ids.size(0)\n","        # print(targets)\n","\n","        outputs = model(text_ids, text_mask)\n","        # print(outputs.shape)\n","        \n","        # print(outputs.shape)\n","\n","        \n","        loss = criterion(outputs, targets)\n","        loss = loss / CONFIG['n_accumulate']\n","        loss.backward()\n","    \n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"],"metadata":{"id":"ltIB44KZyxPt","executionInfo":{"status":"ok","timestamp":1661635886890,"user_tz":-120,"elapsed":15,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        \n","        text_ids = data['text_ids'].to(device, dtype = torch.long)\n","        text_mask = data['text_mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","        \n","        batch_size = text_ids.size(0)\n","\n","        outputs = model(text_ids, text_mask)\n","        # outputs = outputs.argmax(dim=1)\n","        \n","        loss = criterion(outputs, targets)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])   \n","    \n","    gc.collect()\n","    \n","    return epoch_loss"],"metadata":{"id":"U5Ro64pIy4HN","executionInfo":{"status":"ok","timestamp":1661635886890,"user_tz":-120,"elapsed":14,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def run_training(model, optimizer, scheduler, device, num_epochs, fold,train_loader, valid_loader):\n","    # To automatically log gradients\n","    \n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","    \n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","    history = defaultdict(list)\n","    \n","    for epoch in range(1, num_epochs + 1): \n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n","                                           dataloader=train_loader, \n","                                           device=CONFIG['device'], epoch=epoch)\n","        \n","        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n","                                         epoch=epoch)\n","    \n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Valid Loss'].append(val_epoch_loss)\n","        \n","       \n","        \n","        # deep copy the model\n","        if val_epoch_loss <= best_epoch_loss:\n","            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n","            best_epoch_loss = val_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = f\"/content/drive/MyDrive/wanlp/NADI/Saved_Models/bert-base-arabertv02-twitter/Loss-Fold-{fold}.bin\"\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(\"Model Saved\")\n","            \n","        print()\n","    \n","    end = time.time()\n","    time_elapsed = end - start\n","    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n","    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n","    \n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, history"],"metadata":{"id":"HpH2EB0snbV0","executionInfo":{"status":"ok","timestamp":1661635886891,"user_tz":-120,"elapsed":15,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def fetch_scheduler(optimizer):\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == None:\n","        return None\n","        \n","    return scheduler"],"metadata":{"id":"JxT6JHg0nogC","executionInfo":{"status":"ok","timestamp":1661635886891,"user_tz":-120,"elapsed":14,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def prepare_loaders(train,fold):\n","    df_train = train[train.kfold != fold].reset_index(drop=True)\n","    df_valid = train[train.kfold == fold].reset_index(drop=True)\n","    # print(len(df_valid))\n","    sampler = ImbalancedDatasetSampler(df_train)\n","    \n","    train_dataset = TrainDataset(df_train, tokenizer=tokenizer, max_length=CONFIG['max_length'])\n","    valid_dataset = TrainDataset(df_valid, tokenizer=tokenizer, max_length=CONFIG['max_length'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n","                              num_workers=2, sampler=sampler, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n","                              num_workers=2, shuffle=False, pin_memory=True)\n","    \n","    return train_loader, valid_loader"],"metadata":{"id":"x-x9oUAsnqqy","executionInfo":{"status":"ok","timestamp":1661635886892,"user_tz":-120,"elapsed":14,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"T-MsRHzBnZX8"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ih8htg1LoRZC","executionInfo":{"status":"ok","timestamp":1661635915516,"user_tz":-120,"elapsed":28638,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"b6d80c50-94ba-4a3e-879d-d2821068b52e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ,jmnbv"],"metadata":{"id":"yeq4g6QBasWl","executionInfo":{"status":"ok","timestamp":1661635915517,"user_tz":-120,"elapsed":5,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv('/content/drive/MyDrive/wanlp/Datasets/NADI2022-Train/NADI2022-Train/Subtask1/NADI2022_Subtask1_TRAIN.tsv', sep='\\t', lineterminator='\\n')\n","valid = pd.read_csv('/content/drive/MyDrive/wanlp/Datasets/NADI2022-Train/NADI2022-Train/Subtask1/NADI2022_Subtask1_DEV.tsv', sep='\\t', lineterminator='\\n')"],"metadata":{"id":"5dHag8YTn7jE","executionInfo":{"status":"ok","timestamp":1661635917818,"user_tz":-120,"elapsed":2305,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ZLZqgBrJoyaa","executionInfo":{"status":"ok","timestamp":1661635917819,"user_tz":-120,"elapsed":26,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"7d3d7c29-2bbb-45a4-a427-339083fbd869"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         #1_id                                         #2_content #3_label\n","0  TRAIN_15711                         الطرحة في 61 النفر 10 جنيه    yemen\n","1   TRAIN_2257  كله ولا يطالبوا بارض فدك الله ياخدهم الله يعجل...  lebanon\n","2   TRAIN_5618  ' لما اطلقتو تلك التغريدة وقتها كان في واحد سع...  algeria\n","3   TRAIN_7284                                      بجكولى بى خير     iraq\n","4  TRAIN_15841                              يعم القمر براحه علينا    egypt"],"text/html":["\n","  <div id=\"df-54388ef4-3a60-420c-b149-cb40308ad4e2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>#1_id</th>\n","      <th>#2_content</th>\n","      <th>#3_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_15711</td>\n","      <td>الطرحة في 61 النفر 10 جنيه</td>\n","      <td>yemen</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_2257</td>\n","      <td>كله ولا يطالبوا بارض فدك الله ياخدهم الله يعجل...</td>\n","      <td>lebanon</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_5618</td>\n","      <td>' لما اطلقتو تلك التغريدة وقتها كان في واحد سع...</td>\n","      <td>algeria</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_7284</td>\n","      <td>بجكولى بى خير</td>\n","      <td>iraq</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_15841</td>\n","      <td>يعم القمر براحه علينا</td>\n","      <td>egypt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54388ef4-3a60-420c-b149-cb40308ad4e2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-54388ef4-3a60-420c-b149-cb40308ad4e2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-54388ef4-3a60-420c-b149-cb40308ad4e2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["len(train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gB9D4twgo0bI","executionInfo":{"status":"ok","timestamp":1661635917820,"user_tz":-120,"elapsed":24,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"ff61a693-a85f-4e84-89d7-41c5f97ef1a1"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20398"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["train['#3_label'].nunique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYdSpBt2o2HR","executionInfo":{"status":"ok","timestamp":1661635917820,"user_tz":-120,"elapsed":20,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"a3d2b539-8be4-4a11-9c43-df8e151ba0bf"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["valid['#3_label'].nunique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LREmIaISpGJF","executionInfo":{"status":"ok","timestamp":1661635918179,"user_tz":-120,"elapsed":376,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"88a53ea2-1049-4455-bd60-c64b0b027182"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# df_train=pd.concat([train,valid])\n","df_train=train.copy()"],"metadata":{"id":"alyqp1JApKHQ","executionInfo":{"status":"ok","timestamp":1661635918179,"user_tz":-120,"elapsed":5,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["num_classes=df_train['#3_label'].nunique()"],"metadata":{"id":"F8zmQRzrpDra","executionInfo":{"status":"ok","timestamp":1661635918180,"user_tz":-120,"elapsed":6,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["CONFIG = {\"seed\": 42,\n","          \"epochs\": 5,\n","          \"train_batch_size\": 8,\n","          \"valid_batch_size\": 64,\n","          \"max_length\": 512,\n","          \"learning_rate\": 2e-5,\n","          \"scheduler\": 'CosineAnnealingLR',\n","          \"min_lr\": 1e-8,\n","          \"T_max\": 500,\n","          \"weight_decay\": 1e-8,\n","          \"n_fold\": 5,\n","          \"n_accumulate\": 1,\n","          \"num_classes\": 18,\n","          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","          }"],"metadata":{"id":"0_HBDMdYn1Mi","executionInfo":{"status":"ok","timestamp":1661635918180,"user_tz":-120,"elapsed":6,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["tokenizer= AutoTokenizer.from_pretrained('aubmindlab/bert-base-arabertv02-twitter')\n"],"metadata":{"id":"89VbI4nqq17L","executionInfo":{"status":"ok","timestamp":1661635922316,"user_tz":-120,"elapsed":4140,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["3b3239a78c814687864bc1795ae3efce","5444fb225310472bbd78218c7a8a0b9b","26c3b9346d3241928c6613610abf95f4","3f028b3c2f1c4545b9383b5040e3344a","c3374fcc4b0743ecab23fc0e1d6feb0e","3771eb29729f4bd7a0d46131f6c76a69","ba5e6aa9054d48eab6fa7707fec6a336","aeb79b1cfe034281bc0af5dabbaec1aa","f612ce38e39b432ea6817e9f7d574366","6132e20194464c928d0a90e87b92d372","5b6f775f04d646468667678426071c54","17efa215547641c989bd0ec6810de579","21af0283221b43d5afe13bba23ce19b1","df328f1dc29b433bab207cf0579b4869","b4b673d4fde947dd985f6a614c50f6c5","382194c6aafc42ab84076a21b7b3daec","c3af4f9dbf2248d4a3229a03d8ada83b","fc57b3ae3c4a42feb9092f6b6b6dad00","6be05783df994f4fbde921dbc2c7b821","888d1f22517a4dbbb4d8fe2ee4e3967a","525e3abb913e40ab8a4023ba57deac4a","d0fbf9310f554a03a8194c046853f74c","9188ca9e079a4af3b1acb7449f8afaf5","327db4a275814c40801527ac9afe0120","a04bf09ddeed4439a306fe70ea986d5a","890892d949044f8a9d0313446d64b02a","67bf3e8bc5c2400a8cb12916ba2bca2b","2070565993f444148a250a5d1dc265ab","f4a28413b19c4c5cb53c844973838132","c63970cc01b646bc909c84836742299c","006d192b3b90452ca1a82ad34b8804ae","836f302ff3d34c488ab3016c5d08cc44","778be036c7dd4af29077e770858d879d","f8046d1f0d1a4e02b1deea9256af1616","35398e7a36a0430882ebd3cf02b43bcd","aee4de5dcab74524837dc31aa4b28d5d","e53fb0b974524a5382642fe62741b55c","22239d685edb474093acd9cdb8849933","b5a06db0669c4ecb849e85c67fee8d62","a44b5438751e446cadcf8a9b018da3b2","919dfe16bb0448b0b77ea2497d292094","0c06f7024f99432882a27bff32081f3f","f0f3775f8e7c46e2bec1c487b602dd8f","f26346735afb460d84715f2e4a6ba186"]},"outputId":"69811123-1c63-4435-8218-82d994a98e14"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/476 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b3239a78c814687864bc1795ae3efce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/733k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17efa215547641c989bd0ec6810de579"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.19M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9188ca9e079a4af3b1acb7449f8afaf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8046d1f0d1a4e02b1deea9256af1616"}},"metadata":{}}]},{"cell_type":"code","source":["df_train.reset_index(inplace=True)"],"metadata":{"id":"E9sfjlh6qj6t","executionInfo":{"status":"ok","timestamp":1661635922317,"user_tz":-120,"elapsed":21,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n","\n","for fold, ( _, val_) in enumerate(skf.split(X=df_train, y=df_train['#3_label'])):\n","    df_train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","df_train[\"kfold\"] = df_train[\"kfold\"].astype(int)"],"metadata":{"id":"Dq0tSkUrntN4","executionInfo":{"status":"ok","timestamp":1661635922317,"user_tz":-120,"elapsed":20,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["df_train['kfold'].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_0l7FW06mgP","executionInfo":{"status":"ok","timestamp":1661635922318,"user_tz":-120,"elapsed":20,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"19c4b7b2-fc29-48f3-8bde-d044cea6611a"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 2, 3, ..., 0, 1, 2])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","df_train['#3_label'] = le.fit_transform(df_train['#3_label'].values)"],"metadata":{"id":"wOMg6NEVsEkU","executionInfo":{"status":"ok","timestamp":1661635922318,"user_tz":-120,"elapsed":19,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["for fold in range(4, CONFIG['n_fold']):\n","    print(f\"====== Fold: {fold} ======\")\n","\n","    \n","    # Create Dataloaders\n","    train_loader, valid_loader = prepare_loaders(df_train,fold=fold)\n","    \n","    model = NADIModel('aubmindlab/bert-base-arabertv02-twitter')\n","    model.to(CONFIG['device'])\n","    torch.cuda.empty_cache()\n","    \n","    # Define Optimizer and Scheduler\n","    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n","    scheduler = fetch_scheduler(optimizer)\n","    \n","    model, history = run_training(model, optimizer, scheduler,\n","                                  device=CONFIG['device'],\n","                                  num_epochs=CONFIG['epochs'],\n","                                  fold=fold,train_loader=train_loader, valid_loader=valid_loader )\n","    \n","    \n","    del model, history, train_loader, valid_loader\n","    _ = gc.collect()\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":685,"referenced_widgets":["4380a418c08b48909d3697c8cd0bd0ba","86ab8b87c3f34f54b28b5348e3758bd0","a57ef8c59f5f47399b379f7211b7c668","9dccc24494f84a2e884d5c10a4b328de","df1f65971f6e44908dca4503b7039e63","916d8e268a0e478899e51d8fb11e1369","1d7a4bef4a8443b58c83f9ee4fcb8f25","7cf3d0a389714fde8ea655aa9813e792","c62103be1a034b34bf0c6a92ffb3ef4e","f6a0f0cf96774b7eac341848ea33f305","3ecf243994cb4d70992c2405004d8d8b","263fed89e8d442918e8163073fab3d7c","9c15e2d5a4c8488cab38bd293523a1be","8589e42de6394a9e888e35d5aaff991b","35c63fbdec384cafbe47ddaee2cd6784","123787861988452db782976fb2e17b19","3a1d0910d928495a8eaa9a2b6714230d","18133af03efb4498a826b2ff2ffbf2c5","08704f0b3a5e4a1f89998cb5ff91de00","3a7722b23b594201b37c6b2d0eb55e87","b8dd386c36c44240ae8e76040c57c02a","7c1d182ca084488e8e7630b9393e0288"]},"id":"RdoS6yH5nwWG","outputId":"8dfb664c-2efe-4963-a8f6-e0e73b80812f","executionInfo":{"status":"ok","timestamp":1661645123051,"user_tz":-120,"elapsed":9200751,"user":{"displayName":"pink panther","userId":"06900797602742482056"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["====== Fold: 4 ======\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4380a418c08b48909d3697c8cd0bd0ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/516M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263fed89e8d442918e8163073fab3d7c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU: Tesla T4\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2039/2039 [28:12<00:00,  1.20it/s, Epoch=1, LR=1.97e-5, Train_Loss=1.63]\n","100%|██████████| 64/64 [02:17<00:00,  2.15s/it, Epoch=1, LR=1.97e-5, Valid_Loss=1.52]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (inf ---> 1.5193373327542825)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2039/2039 [28:18<00:00,  1.20it/s, Epoch=2, LR=1.88e-5, Train_Loss=1.16]\n","100%|██████████| 64/64 [02:17<00:00,  2.14s/it, Epoch=2, LR=1.88e-5, Valid_Loss=1.44]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.5193373327542825 ---> 1.4417143272517738)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2039/2039 [28:17<00:00,  1.20it/s, Epoch=3, LR=1.74e-5, Train_Loss=0.895]\n","100%|██████████| 64/64 [02:17<00:00,  2.15s/it, Epoch=3, LR=1.74e-5, Valid_Loss=1.45]\n"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2039/2039 [28:17<00:00,  1.20it/s, Epoch=4, LR=1.56e-5, Train_Loss=0.707]\n","100%|██████████| 64/64 [02:17<00:00,  2.14s/it, Epoch=4, LR=1.56e-5, Valid_Loss=1.4]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.4417143272517738 ---> 1.402470578689089)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2039/2039 [28:17<00:00,  1.20it/s, Epoch=5, LR=1.34e-5, Train_Loss=0.541]\n","100%|██████████| 64/64 [02:17<00:00,  2.14s/it, Epoch=5, LR=1.34e-5, Valid_Loss=1.47]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training complete in 2h 33m 1s\n","Best Loss: 1.4025\n","\n"]}]}]}