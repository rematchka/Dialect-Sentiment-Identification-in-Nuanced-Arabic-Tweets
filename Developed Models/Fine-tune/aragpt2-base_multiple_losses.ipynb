{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"57fccb66f7d243ecb79246c21603a603":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed5ea7d87f61463dad6b9c5db5a0fce7","IPY_MODEL_f7639348fd6947febba3e7434f234134","IPY_MODEL_5e0a4acbb6e64395aa9a98d5b8681505"],"layout":"IPY_MODEL_4bcbf766c3de41de825af00b42600c73"}},"ed5ea7d87f61463dad6b9c5db5a0fce7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1920fb64701a48028f14eb55022ccf64","placeholder":"​","style":"IPY_MODEL_6353bac2f5414b68944a3b9772575e0a","value":"Downloading config.json: 100%"}},"f7639348fd6947febba3e7434f234134":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee5276ebaed0461a8d37a229a31b2379","max":843,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ddde168e42c42508d77a308b1ad62dc","value":843}},"5e0a4acbb6e64395aa9a98d5b8681505":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b60e6760ba27427580a7a0ca2a6da3c7","placeholder":"​","style":"IPY_MODEL_f549498befdc43c9a618d0f148f1c07e","value":" 843/843 [00:00&lt;00:00, 24.3kB/s]"}},"4bcbf766c3de41de825af00b42600c73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1920fb64701a48028f14eb55022ccf64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6353bac2f5414b68944a3b9772575e0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee5276ebaed0461a8d37a229a31b2379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ddde168e42c42508d77a308b1ad62dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b60e6760ba27427580a7a0ca2a6da3c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f549498befdc43c9a618d0f148f1c07e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a81be2c57a2c4243ba427411330a6e8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03c883f7589b4ddf9ad2431b9e091773","IPY_MODEL_ad038048801941998def13303185bab1","IPY_MODEL_4716ae0bd06942d195475e418f562f60"],"layout":"IPY_MODEL_e7c7ef6cb46f4ad0a6f94d209de7af9d"}},"03c883f7589b4ddf9ad2431b9e091773":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e740db6f56de4765874980b524be5104","placeholder":"​","style":"IPY_MODEL_481f374c3fb04aca99de318ef0c10102","value":"Downloading vocab.json: 100%"}},"ad038048801941998def13303185bab1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1abbea96af64380aeeafb4dfc6afda2","max":1935314,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc67e087106d4959b95ea2056a2bb429","value":1935314}},"4716ae0bd06942d195475e418f562f60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1bbbcf9089c46a4b1278bb01d12c20b","placeholder":"​","style":"IPY_MODEL_ca6afcff08ec4dca81b589b57dfc4c81","value":" 1.85M/1.85M [00:01&lt;00:00, 2.03MB/s]"}},"e7c7ef6cb46f4ad0a6f94d209de7af9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e740db6f56de4765874980b524be5104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"481f374c3fb04aca99de318ef0c10102":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1abbea96af64380aeeafb4dfc6afda2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc67e087106d4959b95ea2056a2bb429":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1bbbcf9089c46a4b1278bb01d12c20b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca6afcff08ec4dca81b589b57dfc4c81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"add0e37764d54aad9468b39c989bab29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fc76f085b0e4588bbd25282ec2d983d","IPY_MODEL_80e18347534b4c47aae6b463bf87650a","IPY_MODEL_f290dfbddd704f9cbc1bbc50800d4516"],"layout":"IPY_MODEL_7c453fb00ac5489a851c11e72f8d78e6"}},"9fc76f085b0e4588bbd25282ec2d983d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2ba4b042767405da91000fbb2d39e28","placeholder":"​","style":"IPY_MODEL_311350cf2ae04b78bcbe1c7d62d719fd","value":"Downloading merges.txt: 100%"}},"80e18347534b4c47aae6b463bf87650a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ca94cb69271412885aaa3862e7818f3","max":1497508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff5313664f904e529e66ebfe6f800f45","value":1497508}},"f290dfbddd704f9cbc1bbc50800d4516":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2159900cdc84743a50a98ca1dc3419d","placeholder":"​","style":"IPY_MODEL_5c361df58f80483ca5813e9e4da3e3ed","value":" 1.43M/1.43M [00:01&lt;00:00, 1.61MB/s]"}},"7c453fb00ac5489a851c11e72f8d78e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2ba4b042767405da91000fbb2d39e28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"311350cf2ae04b78bcbe1c7d62d719fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ca94cb69271412885aaa3862e7818f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff5313664f904e529e66ebfe6f800f45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2159900cdc84743a50a98ca1dc3419d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c361df58f80483ca5813e9e4da3e3ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6a0950cdf144911a1927042871a17f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66797fd1ad054ae992fe4a624cdaebd4","IPY_MODEL_c07a6a760d664eb0ab2aca59bc66428a","IPY_MODEL_520318c7827b46f2961eba07b98e8089"],"layout":"IPY_MODEL_1dd9f1b258c94a8394e70fb753557da4"}},"66797fd1ad054ae992fe4a624cdaebd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1249dd83cb3b451091c7b5b439f60650","placeholder":"​","style":"IPY_MODEL_92806c3935dc4e3f91fb67f6249e3bff","value":"Downloading tokenizer.json: 100%"}},"c07a6a760d664eb0ab2aca59bc66428a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c101be9f684471a97145e10478865d1","max":4519765,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5782c97ff99645c29aeb4ccdcaa311ff","value":4519765}},"520318c7827b46f2961eba07b98e8089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7581ae4395043318a914702d267ecd1","placeholder":"​","style":"IPY_MODEL_e18f15c56bd94ca992c7a95e3ba64513","value":" 4.31M/4.31M [00:01&lt;00:00, 3.93MB/s]"}},"1dd9f1b258c94a8394e70fb753557da4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1249dd83cb3b451091c7b5b439f60650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92806c3935dc4e3f91fb67f6249e3bff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c101be9f684471a97145e10478865d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5782c97ff99645c29aeb4ccdcaa311ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7581ae4395043318a914702d267ecd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e18f15c56bd94ca992c7a95e3ba64513":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ca5a996a5124f79901e3fdef70c91b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64041a0521f54576875a1ae61242a264","IPY_MODEL_0d3c119add5043739d7d06826dd51a58","IPY_MODEL_d5c47d7e4c6a41efbbedc22f70bf0447"],"layout":"IPY_MODEL_a7410c88ab6b42e49911dc37220ae60a"}},"64041a0521f54576875a1ae61242a264":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4602948403a046d4a6a09c1ce0c501ad","placeholder":"​","style":"IPY_MODEL_60dc8fa56f914b49b406a3cde92db835","value":"Downloading pytorch_model.bin: 100%"}},"0d3c119add5043739d7d06826dd51a58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb320e07681242c98052146ac750bc16","max":552618653,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ea6a009458946a5b781960551cbc15e","value":552618653}},"d5c47d7e4c6a41efbbedc22f70bf0447":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a923eea457694ccdac603de5e76aadc9","placeholder":"​","style":"IPY_MODEL_52ca27d461944a27a9b3bb89f881ebc9","value":" 527M/527M [00:31&lt;00:00, 17.8MB/s]"}},"a7410c88ab6b42e49911dc37220ae60a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4602948403a046d4a6a09c1ce0c501ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60dc8fa56f914b49b406a3cde92db835":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb320e07681242c98052146ac750bc16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ea6a009458946a5b781960551cbc15e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a923eea457694ccdac603de5e76aadc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52ca27d461944a27a9b3bb89f881ebc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install sentencepiece\n","!pip  install transformers\n","!pip install pytorch-ignite\n","!pip install datasets\n","\n"],"metadata":{"id":"vMmciFBRyRFe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661622464859,"user_tz":-120,"elapsed":33074,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"outputId":"2594685f-fe1f-4901-a78d-f3de641d86a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 19.8 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 31.9 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 40.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 41.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.9-py3-none-any.whl (259 kB)\n","\u001b[K     |████████████████████████████████| 259 kB 30.9 MB/s \n","\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.12.1+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.4.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 27.4 MB/s \n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 65.3 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 71.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 65.9 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtS4CD_krp3d"},"outputs":[],"source":["import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch\n","from transformers import AutoModel\n","import torch.nn.functional as F\n","from sklearn.metrics import f1_score, accuracy_score, classification_report\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","# Any results you write to the current directory are saved as output.\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","from transformers import BertTokenizer,BertModel\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,Dataset\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from torch.optim import AdamW\n","from tqdm import tqdm\n","from argparse import ArgumentParser\n","from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n","from ignite.metrics import Accuracy, Loss\n","from ignite.engine.engine import Engine, State, Events\n","from ignite.handlers import EarlyStopping\n","from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n","from ignite.utils import convert_tensor\n","from torch.optim.lr_scheduler import ExponentialLR\n","import warnings  \n","warnings.filterwarnings('ignore')\n","import gc\n","import copy\n","import time\n","import random\n","import string\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Pytorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Utils\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, KFold\n","from transformers import AutoTokenizer, AutoModel, AdamW\n","import random\n","import os\n","from urllib import request\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n","\n","from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n","from transformers.data.processors import SingleSentenceClassificationProcessor\n","from transformers import Trainer , TrainingArguments\n","from transformers.trainer_utils import EvaluationStrategy\n","from transformers.data.processors.utils import InputFeatures\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"ARjNBDtgwfVJ"}},{"cell_type":"code","source":["class TrainDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = max_length\n","        self.tokenizer = tokenizer\n","        self.text = df['#2_content'].values\n","        self.label=df['#3_label'].values\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        # summary = self.summary[index]\n","        inputs_text = self.tokenizer.encode_plus(\n","                                text,\n","                                truncation=True,\n","                                add_special_tokens=True,\n","                                max_length=self.max_len,\n","                                padding='max_length'\n","                            )\n","        \n","                            \n","        target = self.label[index]\n","        \n","        text_ids = inputs_text['input_ids']\n","        text_mask = inputs_text['attention_mask']\n","        \n","       \n","        \n","        \n","        return {\n","            \n","            'text_ids': torch.tensor(text_ids, dtype=torch.long),\n","            'text_mask': torch.tensor(text_mask, dtype=torch.long),\n","            'target': torch.tensor(target, dtype=torch.float)\n","        }"],"metadata":{"id":"lLRNRjusoELI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","# from sklearn.model_selection import train_test_split\n","# from torch.utils.data import Dataset, DataLoader\n","# import Dataset\n","# import os\n","# import numpy as np\n","# from emoji import UNICODE_EMOJI\n","# import TweetNormalizer\n","# import re\n","# import text_normalization\n","\n","\n","# dic = {\n","#       \"egypt\": 'المصرية',\n","# \t  \"nile\": 'المصرية',\n","# \t  \"msa\": \"اللغة العربية الفصحى\",\n","# \t  \"magreb\": \"المغربية\",\n","# \t  \"gulf\": \"الخليجية\",\n","# \t  \"levant\": \"الشامية\"\n","# }\n","\n","# def is_emoji(s):\n","#     return s in UNICODE_EMOJI\n","\n","# # add space near your emoji\n","# def add_space(text):\n","#     return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n","\n","# def preprocess(text, lang='ar'):\n","#     if lang == 'ar':\n","#         sent = add_space(text)\n","#         sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n","#         sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n","#         sent = sent.replace('_', ' ')\n","#         sent = sent.replace('#', ' ')\n","#     else:\n","#         sent = add_space(text)\n","#         sent = re.sub(r'(?:@[\\w_]+)', \"@user\", sent)\n","#         sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"http\", sent)\n","#         sent = sent.replace('_', ' ')\n","#         sent = sent.replace('#', ' ')\n","\n","#     return sent\n","\n","# def prepare_text(df, col='tweet'):\n","#     if col == 'tweet':\n","#         df['dialect'] = df['dialect'].map(dic)   \n","#     for i in range(df.shape[0]):\n","#         df.loc[i, col] = df.loc[i, 'dialect'] + ' [SEP] ' + df.loc[i, col]\n","\n","\n","#     return df\n","\n","# def augment_data(df_train,text_col,label_col):\n","#     df_aug = pd.DataFrame(columns=[text_col, label_col)\n","#     dic_dup = {1: 3,\n","#                0: 1\n","#                }\n","#     for i in range(df_train.shape[0]):\n","#         current = df_train.iloc[i]\n","#         text = current[text_col]\n","#         label_cat = current[label_col]\n","\n","#         aug_ratio = dic_dup[label_cat]\n","#         for k in range(aug_ratio):\n","#             tokens = text.split(' ')\n","#             l = len(tokens)\n","#             n = int(0.1 * l)\n","#             indices = np.random.choice(l, n, replace=False)\n","#             for j in range(len(indices)):\n","#                 tokens[indices[j]] = '[MASK]'\n","#             new_text = ' '.join(tokens)\n","#             entry = {text_col: new_text, label_col: label_cat}\n","#             df_aug = df_aug.append(entry, ignore_index=True)\n","#     df_aug.drop_duplicates(subset=[text_col], keep='first', inplace=True)\n","#     df = pd.concat([df_train,df_aug])\n","#     return df\n"],"metadata":{"id":"0ZOanFa2wz3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# '''\n","# Created by: Mohamed Salem Elhady  \n","# Email: mohamed.elaraby@alumni.ubc.ca\n","# Text Normalization: V1 \n","# '''\n","# import sys\n","# import re\n","# import emojis\n","# from emoji import UNICODE_EMOJI\n","# #sys.setdefaultencoding('utf-8')\n","# ##########################Clean Text Data #######################################\n","# ########################Global Variable Declaration##############################\n","# list_seeds = ['سبحان الله', 'الله أكبر', 'اللهم', 'بسم الله', 'يا رب', 'العضيم', 'سبحان', 'يارب', 'قران', 'quran',\n","#               'حديث', 'hadith', 'صلاه_الفجر', '﴾', 'ﷺ', 'صحيح البخاري', 'صحيح مسلم', 'يآرب', 'سورة']\n","# MaxWordPerTweet=7\n","# #################################################################################\n","# def is_emoji(s):\n","#     return s in UNICODE_EMOJI\n","\n","# # add space near your emoji\n","# def add_space(text):\n","#     return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n","\n","# def clean(sent):\n","#     \"\"\"clean data from any English char, emoticons, underscore, and repeated > 2\n","#     str -> str\"\"\"\n","#     p1 = re.compile('\\W')\n","#     p2 = re.compile('\\s+')\n","#     sent = re.sub(r\"http\\S+\", \"\", sent)\n","#     sent = ReplaceThreeOrMore(sent)\n","#     sent = remove_unicode_diac(sent)\n","#     sent = sent.replace('_', ' ')\n","#     sent = re.sub(r'[A-Za-z0-9]', r'', sent)\n","#     sent = re.sub(p1, ' ', sent)\n","#     sent = re.sub(p2, ' ', sent)\n","#     return sent\n","\n","# def tokenize_emojis(tweet):\n","#     return list(emojis.get(tweet))\n","\n","# def replace_emoji(sent):\n","#     emoji_pattern = re.compile(\"[\"\n","#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","#                                \"]+\", flags=re.UNICODE)\n","#     return emoji_pattern.sub(r'[MASK]', sent)\n","\n","# def preprocess(tweet):\n","#     tweet = add_space(tweet)\n","#     emos = tokenize_emojis(tweet)\n","#     sent = remove_unicode_diac(tweet)\n","#     sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n","#     sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n","#     sent = sent.replace('_', ' ')\n","#     sent = sent.replace('#', ' ')\n","#     if len(emos) > 0:\n","#         sent = sent + ' [SEP] '  + ' '.join(emos)\n","#     #    #sent = sent + ' [SEP] ' + clean_unicode(tweet) + ' [SEP] ' + ' '.join(emos)\n","\n","#     #else:\n","#     #    sent = sent + ' [SEP] ' + clean_unicode(tweet)\n","#     return sent\n","\n","# def preprocess_last(tweet, k=0):\n","#     emos = tokenize_emojis(tweet)\n","#     sent = remove_unicode_diac(tweet)\n","#     sent = re.sub(r'(?:@[\\w_]+)', \"\", sent)\n","#     sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"\", sent)\n","#     sent = sent.replace('_', ' ')\n","#     sent = sent.replace('#', ' ')\n","#     if k == 0:\n","#         sent = sent\n","#     elif k ==1 :\n","#         sent = sent + ' [SEP] ' + ' '.join(emos)\n","#     elif k==2 :\n","#         sent = sent + ' [SEP] ' + clean_unicode(tweet) + ' [SEP] ' + ' '.join(emos)\n","#     elif k == 3:\n","#         sent = sent + ' [SEP] ' + clean_unicode(tweet)\n","#     else:\n","#         sent = replace_emoji(sent)\n","#         sent = sent + ' [SEP] ' + clean_unicode(tweet) + ' [SEP] ' + ' '.join(emos)\n","\n","#     return sent\n","\n","\n","# def normalize(sent):\n","#     \"\"\"clean data from any English char, emoticons, underscore, and repeated > 2\n","#     str -> str\"\"\"\n","#     sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n","#     sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n","#     #sent = re.sub(r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", \"hashtag\", sent)\n","#     sent = ReplaceThreeOrMore(sent)\n","#     sent = remove_unicode_diac(sent)\n","#     sent = sent.replace('_', ' ')\n","#     return sent\n","\n","# def ReplaceThreeOrMore(s):\n","#     # pattern to look for three or more repetitions of any character, including\n","#     # newlines.\n","#     pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n","#     return pattern.sub(r\"\\1\\1\", s)\n","# def norm_alif(text):\n","#     text = text.replace(u\"\\u0625\", u\"\\u0627\")  # HAMZA below, with LETTER ALEF\n","#     #text = text.replace(u\"\\u0621\", u\"\\u0627\")  # HAMZA, with LETTER ALEF\n","#     text = text.replace(u\"\\u0622\", u\"\\u0627\")  # ALEF WITH MADDA ABOVE, with LETTER ALEF\n","#     text = text.replace(u\"\\u0623\", u\"\\u0627\")  # ALEF WITH HAMZA ABOVE, with LETTER ALEF\n","#     return text\n","# def remove_unicode_diac(text):\n","#     \"\"\"Takes Arabic in utf-8 and returns same text without diac\"\"\"\n","#     # Replace diacritics with nothing\n","#     text = text.replace(u\"\\u064B\", \"\")  # fatHatayn\n","#     text = text.replace(u\"\\u064C\", \"\")  # Dammatayn\n","#     text = text.replace(u\"\\u064D\", \"\")  # kasratayn\n","#     text = text.replace(u\"\\u064E\", \"\")  # fatHa\n","#     text = text.replace(u\"\\u064F\", \"\")  # Damma\n","#     text = text.replace(u\"\\u0650\", \"\")  # kasra\n","#     text = text.replace(u\"\\u0651\", \"\")  # shaddah\n","#     text = text.replace(u\"\\u0652\", \"\")  # sukuun\n","#     text = text.replace(u\"\\u0670\", \"`\")  # dagger 'alif\n","#     return text\n","# def norm_taa(text):\n","#     text=text.replace(u\"\\u0629\", u\"\\u0647\") # taa' marbuuTa, with haa'\n","#     #text=text.replace(u\"\\u064A\", u\"\\u0649\") # yaa' with 'alif maqSuura\n","#     return text\n","# def norm_yaa(text):\n","#     if len(text)!=0:\n","#         if text[-1] == u\"\\u064A\":\n","#             text = text[:-1] + text[-1].replace(u\"\\u064A\", u\"\\u0649\")  # yaa' with 'alif maqSuura\n","#     return text\n","\n","# def NormForWord2Vec(text):\n","#     text=norm_taa(text)\n","#     text=norm_yaa(text)\n","#     text=norm_alif(text)\n","#     return text\n","\n","# def remove_nonunicode2(Tweet):\n","#     ## defining set of unicode ##\n","#     #u\"\"\n","#     #Tweet=Tweet.decode(\"utf-8\")\n","#     UniLex={ ## This is list of all arabic unicode characters in addition to space (to separate words)\n","#             u\"\\u0622\",\n","#             u\"\\u0626\",\n","#             u\"\\u0628\",\n","#             u\"\\u062a\",\n","#             u\"\\u062c\",\n","#             u\"\\u06af\",\n","#             u\"\\u062e\",\n","#             u\"\\u0630\",\n","#             u\"\\u0632\",\n","#             u\"\\u0634\",\n","#             u\"\\u0636\",\n","#             u\"\\u0638\",\n","#             u\"\\u063a\",\n","#             u\"\\u0640\",\n","#             u\"\\u0642\",\n","#             u\"\\u0644\",\n","#             u\"\\u0646\",\n","#             u\"\\u0648\",\n","#             u\"\\u064a\",\n","#             u\"\\u0670\",\n","#             u\"\\u067e\",\n","#             u\"\\u0686\",\n","#             u\"\\u0621\",\n","#             u\"\\u0623\",\n","#             u\"\\u0625\",\n","#             u\"\\u06a4\",\n","#             u\"\\u0627\",\n","#             u\"\\u0629\",\n","#             u\"\\u062b\",\n","#             u\"\\u062d\",\n","#             u\"\\u062f\",\n","#             u\"\\u0631\",\n","#             u\"\\u0633\",\n","#             u\"\\u0635\",\n","#             u\"\\u0637\",\n","#             u\"\\u0639\",\n","#             u\"\\u0641\",\n","#             u\"\\u0643\",\n","#             u\"\\u0645\",\n","#             u\"\\u0647\",\n","#             u\"\\u0649\",\n","#             u\"\\u0671\",\n","#             ' ',\n","#             '\\n'\n","#           }\n","#     fin_tweet=\"\"\n","#     for c in Tweet:\n","#         if c in UniLex:\n","#            fin_tweet=fin_tweet+c\n","#     return fin_tweet\n","\n","# ###### Heuristics Calculations ######\n","# def diac_counter(text):\n","#     #text=text.decode(\"utf-8\")\n","#     diac = [u\"\\u064B\",u\"\\u064C\", u\"\\u064D\", u\"\\u064E\", u\"\\u064F\", u\"\\u0650\", u\"\\u0651\", u\"\\u0652\", u\"\\u0670\"]\n","#     diac_count=0\n","#     for d in diac:\n","#         diac_count+=text.count(d)\n","# #         if d in text:\n","# #             print(d)\n","# #             diac_count+=1\n","#     return diac_count\n","# def check_seed(list_seeds, text):\n","#     \"\"\n","#     for word in list_seeds:\n","#         text = text.lower()\n","#         if word.decode(\"utf-8\") in text:\n","#             return True\n","#     return False\n","# def EnglishCount(text):\n","#     printable = ['e', 'a', 'o', 't', 'i']\n","#     count = 0\n","#     for ch in printable:\n","#         count += text.count(ch.lower())\n","#     return count\n","# ########################################\n","\n","\n","\n","# def eliminate_single_char_words(Tweet):\n","#     parts = Tweet.split(\" \")\n","#     cleaned_line_parts = []\n","#     for P in parts:\n","#         if len(P) != 1:\n","#             cleaned_line_parts.append(P)\n","#     cleaned_line = ' '.join(cleaned_line_parts)\n","#     return cleaned_line\n","# def clean_unicode(Tweet):\n","#     tweet=normalize(Tweet.strip(\"\\n\"))\n","#     if len(tweet) !=0:\n","#         sentence = []\n","#         for word in tweet.split(\" \"):\n","#             word = remove_unicode_diac(word)\n","#             word = norm_alif(word)\n","#             word = norm_taa(word)\n","#             word = norm_yaa(word)\n","#             word = normalize(word)\n","#             sentence.append(word)\n","#         tweet = ' '.join(sentence)\n","#         tweet =remove_nonunicode2(tweet)\n","#         tweet =eliminate_single_char_words(tweet)\n","#     return tweet\n","\n","# def clean_unicode2(Tweet):\n","#     KeepUniOnly(Tweet)\n","#     tweet=normalize(Tweet.strip(\"\\n\"))\n","#     if len(tweet) !=0:\n","#         sentence = []\n","#         for word in tweet.split(\" \"):\n","#             word = remove_unicode_diac(word)\n","#             word = normalize(word)\n","#             sentence.append(word)\n","#         tweet = ' '.join(sentence)\n","#         tweet =remove_nonunicode2(tweet)\n","#         tweet =eliminate_single_char_words(tweet)\n","#     return tweet\n","\n","# def NormCorpusFinal(Tweet):\n","#     tweet=KeepUniOnly(Tweet)\n","#     tweet=NormForWord2Vec(tweet)\n","#     return tweet\n","\n","# def KeepUniOnly(Tweet):## this one is without normalization\n","#     tweet=Tweet.replace(\"# \",\" \")\n","#     tweet=tweet.replace(\"#\",\" \")\n","#     tweet=tweet.replace(\"_\",\" \")\n","#     tweet=tweet.replace(u\"\\u0657\",\" \")\n","#     tweet=tweet.replace(\"\\n\",\" \")\n","#     tweet=remove_nonunicode2(tweet)\n","#     tweet=eliminate_single_char_words(tweet)\n","#     tweet=ReplaceThreeOrMore(tweet)\n","#     return tweet\n","\n","# def get_charset(rawtext):\n","#     chars = sorted(list(set(rawtext)))\n","#     return chars\n","\n","# def DialectChecker(text):\n","#     ##Based on Hueristics done by Hassan\n","#     if (diac_counter(text)>5 or check_seed(list_seeds,text) or EnglishCount(text)>4 or \"<URL>\"  in text\n","#         or text.count('#') >2 or '\"'  in text or text.count('@') or \"\\\"RT\" in text or len(text.split(\" \")) <7):\n","#         return False\n","#     else:\n","#         return True\n","\n","# ###############################################################\n","# '''\n","# Fread=open(\"Egypt_portion.txt\",'r')\n","# Fwriter=open(\"Egypt_portion_norm.txt\",'w')\n","# for line in Fread:\n","#     cleaned_line=clean_unicode_for_w2v(line)\n","#     Fwriter.write(str(cleaned_line))\n","# Fwriter.close()\n","# '''"],"metadata":{"id":"QcOa9agTwhIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Losses"],"metadata":{"id":"iVcFbe1Bvcqh"}},{"cell_type":"code","source":["class F1_Loss(nn.Module):\n","    '''Calculate F1 score. Can work with gpu tensors\n","    \n","    The original implmentation is written by Michal Haltuf on Kaggle.\n","    \n","    Returns\n","    -------\n","    torch.Tensor\n","        `ndim` == 1. epsilon <= val <= 1\n","    \n","    Reference\n","    ---------\n","    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n","    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n","    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n","    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n","    '''\n","    def __init__(self, epsilon=1e-7):\n","        super().__init__()\n","        self.epsilon = epsilon\n","        \n","    def forward(self, y_pred, y_true,):\n","        # assert y_pred.ndim == 2\n","        # assert y_true.ndim == 1\n","        # print(y_pred.shape)\n","        # print(y_true.shape)\n","        # y_pred[y_pred<0.5]=0\n","        # y_pred[y_pred>=0.5]=0\n","\n","\n","        \n","        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 18).to(torch.float32)\n","        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n","        \n","        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n","        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n","        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n","        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n","        f1=f1.detach()\n","        # print(f1.shape)\n","        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n","        # y_true=y_true.reshape((y_true.shape[0], 1))\n","\n","        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n","        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n","\n","\n","        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n","        # print(y_pred)\n","        # print(y_true_one_hot)\n","        CE =torch.nn.CrossEntropyLoss(weight=( 1 - f1))(y_pred, y_true_one_hot)\n","        # loss = ( 1 - f1)  * CE\n","        return  CE.mean()"],"metadata":{"id":"RGw6mbs0uIlN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Recall_Loss(nn.Module):\n","    '''Calculate Recall score. Can work with gpu tensors\n","    \n","    The original implmentation is written by Michal Haltuf on Kaggle.\n","    \n","    Returns\n","    -------\n","    torch.Tensor\n","        `ndim` == 1. epsilon <= val <= 1\n","    \n","    Reference\n","    ---------\n","    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n","    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n","    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n","    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n","    '''\n","    def __init__(self, epsilon=1e-7):\n","        super().__init__()\n","        self.epsilon = epsilon\n","        \n","    def forward(self, y_pred, y_true,):\n","        # assert y_pred.ndim == 2\n","        # assert y_true.ndim == 1\n","        # print(y_pred.shape)\n","        # print(y_true.shape)\n","        # y_pred[y_pred<0.5]=0\n","        # y_pred[y_pred>=0.5]=0\n","\n","\n","        \n","        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 18).to(torch.float32)\n","        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n","        \n","        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n","        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n","        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        # f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n","        # f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n","        # f1=f1.detach()\n","        # print(f1.shape)\n","        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n","        # y_true=y_true.reshape((y_true.shape[0], 1))\n","\n","        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n","        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n","\n","\n","        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n","        # print(y_pred)\n","        # print(y_true_one_hot)\n","        recall=recall.detach()\n","        CE =torch.nn.CrossEntropyLoss(weight=( 1 - recall))(y_pred, y_true_one_hot)\n","        # loss = ( 1 - f1)  * CE\n","        return  CE.mean()"],"metadata":{"id":"Pdd02bGivpr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Based on https://github.com/AbdelkaderMH/iSarcasmEval/blob/8f28f24ebfb641415a604329ed859506ae687148/focal_loss.py\n","class BinaryFocalLoss(nn.Module):\n","    \"\"\"\n","    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n","    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n","        Focal_Loss= -1*alpha*(1-pt)*log(pt)\n","    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n","    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n","                    focus on hard misclassified example\n","    :param reduction: `none`|`mean`|`sum`\n","    :param **kwargs\n","        balance_index: (int) balance class index, should be specific when alpha is float\n","    \"\"\"\n","\n","    def __init__(self, alpha=3, gamma=2, ignore_index=None, reduction='mean', **kwargs):\n","        super(BinaryFocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.smooth = 1e-6  # set '1e-4' when train with FP16\n","        self.ignore_index = ignore_index\n","        self.reduction = reduction\n","\n","        assert self.reduction in ['none', 'mean', 'sum']\n","\n","        # if self.alpha is None:\n","        #     self.alpha = torch.ones(2)\n","        # elif isinstance(self.alpha, (list, np.ndarray)):\n","        #     self.alpha = np.asarray(self.alpha)\n","        #     self.alpha = np.reshape(self.alpha, (2))\n","        #     assert self.alpha.shape[0] == 2, \\\n","        #         'the `alpha` shape is not match the number of class'\n","        # elif isinstance(self.alpha, (float, int)):\n","        #     self.alpha = np.asarray([self.alpha, 1.0 - self.alpha], dtype=np.float).view(2)\n","\n","        # else:\n","        #     raise TypeError('{} not supported'.format(type(self.alpha)))\n","\n","    def forward(self, output, target):\n","        prob = torch.sigmoid(output)\n","        prob = torch.clamp(prob, self.smooth, 1.0 - self.smooth)\n","\n","        valid_mask = None\n","        if self.ignore_index is not None:\n","            valid_mask = (target != self.ignore_index).float()\n","\n","        pos_mask = (target == 1).float()\n","        neg_mask = (target == 0).float()\n","        if valid_mask is not None:\n","            pos_mask = pos_mask * valid_mask\n","            neg_mask = neg_mask * valid_mask\n","\n","        pos_weight = (pos_mask * torch.pow(1 - prob, self.gamma)).detach()\n","        pos_loss = -pos_weight * torch.log(prob)  # / (torch.sum(pos_weight) + 1e-4)\n","\n","        neg_weight = (neg_mask * torch.pow(prob, self.gamma)).detach()\n","        neg_loss = -self.alpha * neg_weight * F.logsigmoid(-output)  # / (torch.sum(neg_weight) + 1e-4)\n","        loss = pos_loss + neg_loss\n","        loss = loss.mean()\n","        return loss\n","\n","\n","class FocalLoss_Ori(nn.Module):\n","    \"\"\"\n","    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n","    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n","    Focal_Loss= -1*alpha*((1-pt)**gamma)*log(pt)\n","    Args:\n","        num_class: number of classes\n","        alpha: class balance factor\n","        gamma:\n","        ignore_index:\n","        reduction:\n","    \"\"\"\n","\n","    def __init__(self, num_class, alpha=None, gamma=2, ignore_index=None, reduction='mean'):\n","        super(FocalLoss_Ori, self).__init__()\n","        self.num_class = num_class\n","        self.gamma = gamma\n","        self.reduction = reduction\n","        self.smooth = 1e-4\n","        self.ignore_index = ignore_index\n","        self.alpha = alpha\n","        if alpha is None:\n","            self.alpha = torch.ones(num_class, )\n","        elif isinstance(alpha, (int, float)):\n","            self.alpha = torch.as_tensor([alpha] * num_class)\n","        elif isinstance(alpha, (list, np.ndarray)):\n","            self.alpha = torch.as_tensor(alpha)\n","        if self.alpha.shape[0] != num_class:\n","            raise RuntimeError('the length not equal to number of class')\n","\n","        # if isinstance(self.alpha, (list, tuple, np.ndarray)):\n","        #     assert len(self.alpha) == self.num_class\n","        #     self.alpha = torch.Tensor(list(self.alpha))\n","        # elif isinstance(self.alpha, (float, int)):\n","        #     assert 0 < self.alpha < 1.0, 'alpha should be in `(0,1)`)'\n","        #     assert balance_index > -1\n","        #     alpha = torch.ones((self.num_class))\n","        #     alpha *= 1 - self.alpha\n","        #     alpha[balance_index] = self.alpha\n","        #     self.alpha = alpha\n","        # elif isinstance(self.alpha, torch.Tensor):\n","        #     self.alpha = self.alpha\n","        # else:\n","        #     raise TypeError('Not support alpha type, expect `int|float|list|tuple|torch.Tensor`')\n","\n","    def forward(self, logit, target):\n","        # assert isinstance(self.alpha,torch.Tensor)\\\n","        N, C = logit.shape[:2]\n","        alpha = self.alpha.to(logit.device)\n","        prob = F.softmax(logit, dim=1)\n","        if prob.dim() > 2:\n","            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n","            prob = prob.view(N, C, -1)\n","            prob = prob.transpose(1, 2).contiguous()  # [N,C,d1*d2..] -> [N,d1*d2..,C]\n","            prob = prob.view(-1, prob.size(-1))  # [N,d1*d2..,C]-> [N*d1*d2..,C]\n","        ori_shp = target.shape\n","        target = target.view(-1, 1)  # [N,d1,d2,...]->[N*d1*d2*...,1]\n","        valid_mask = None\n","        if self.ignore_index is not None:\n","            valid_mask = target != self.ignore_index\n","            target = target * valid_mask\n","\n","        # ----------memory saving way--------\n","        prob = prob.gather(1, target).view(-1) + self.smooth  # avoid nan\n","        logpt = torch.log(prob)\n","        # alpha_class = alpha.gather(0, target.view(-1))\n","        alpha_class = alpha[target.squeeze().long()]\n","        class_weight = -alpha_class * torch.pow(torch.sub(1.0, prob), self.gamma)\n","        loss = class_weight * logpt\n","        if valid_mask is not None:\n","            loss = loss * valid_mask.squeeze()\n","\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","            if valid_mask is not None:\n","                loss = loss.sum() / valid_mask.sum()\n","        elif self.reduction == 'none':\n","            loss = loss.view(ori_shp)\n","        return loss\n","\n","\n","\n","def weighted_binary_cross_entropy(input, targets, pos_weight, weight=None, size_average=True, reduce=True):\n","    \"\"\"\n","    Args:\n","        sigmoid_x: predicted probability of size [N,C], N sample and C Class. Eg. Must be in range of [0,1], i.e. Output from Sigmoid.\n","        targets: true value, one-hot-like vector of size [N,C]\n","        pos_weight: Weight for postive sample\n","    \"\"\"\n","    sigmoid_x = torch.sigmoid(input)\n","    if not (targets.size() == sigmoid_x.size()):\n","        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(targets.size(), sigmoid_x.size()))\n","\n","    loss = -pos_weight* targets * sigmoid_x.log() - (1-targets)*(1-sigmoid_x).log()\n","\n","    if weight is not None:\n","        loss = loss * weight\n","\n","    if not reduce:\n","        return loss\n","    elif size_average:\n","        return loss.mean()\n","    else:\n","        return loss.sum()\n","\n","class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight= 1, weight=None, PosWeightIsDynamic= True, WeightIsDynamic= False, size_average=True, reduce=True):\n","        \"\"\"\n","        Args:\n","            pos_weight = Weight for postive samples. Size [1,C]\n","            weight = Weight for Each class. Size [1,C]\n","            PosWeightIsDynamic: If True, the pos_weight is computed on each batch. If pos_weight is None, then it remains None.\n","            WeightIsDynamic: If True, the weight is computed on each batch. If weight is None, then it remains None.\n","        \"\"\"\n","        super().__init__()\n","\n","        #self.register_buffer('weight', weight)\n","        #self.register_buffer('pos_weight', pos_weight)\n","        self.size_average = size_average\n","        self.reduce = reduce\n","        self.PosWeightIsDynamic = PosWeightIsDynamic\n","\n","    def forward(self, input, target):\n","        # pos_weight = Variable(self.pos_weight) if not isinstance(self.pos_weight, Variable) else self.pos_weight\n","        if self.PosWeightIsDynamic:\n","            positive_counts = target.sum(dim=0)\n","            nBatch = len(target)\n","            self.pos_weight = (nBatch - positive_counts)/(positive_counts +1e-5)\n","\n","\n","        return weighted_binary_cross_entropy(input, target,\n","                                                self.pos_weight,\n","                                                weight=None,\n","                                                size_average=self.size_average,\n","                                                reduce=self.reduce)\n","\n","\n","class WeightedCELoss(nn.Module):\n","    def __init__(self, size_average=True, reduce=True):\n","        \"\"\"\n","        Args:\n","            pos_weight = Weight for postive samples. Size [1,C]\n","            weight = Weight for Each class. Size [1,C]\n","            PosWeightIsDynamic: If True, the pos_weight is computed on each batch. If pos_weight is None, then it remains None.\n","            WeightIsDynamic: If True, the weight is computed on each batch. If weight is None, then it remains None.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.size_average = size_average\n","        self.reduce = reduce\n","\n","    def forward(self, input, target):\n","        positive_counts = target.sum(dim=0)\n","        nBatch = len(target)\n","        pos_weight = (nBatch - positive_counts)/(positive_counts +1e-5)\n","        neg_count = nBatch - positive_counts\n","        neg_weight = (nBatch - neg_count)/(neg_count +1e-5)\n","\n","        weight = torch.tensor([neg_weight, pos_weight], device=target.device)\n","  \n","\n","\n","        return F.cross_entropy(input, target, weight=weight)\n","\n","\n","\n","class FLMultiLoss(nn.Module):\n","    def __init__(self, gamma= 2):\n","        \"\"\"\n","        Args:\n","            pos_weight = Weight for postive samples. Size [1,C]\n","            weight = Weight for Each class. Size [1,C]\n","            PosWeightIsDynamic: If True, the pos_weight is computed on each batch. If pos_weight is None, then it remains None.\n","            WeightIsDynamic: If True, the weight is computed on each batch. If weight is None, then it remains None.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.gamma = gamma\n","    def forward(self, input, target):\n","\n","\n","        return focal_binary_cross_entropy(input, target, gamma=2)\n","\n","def EntropyLoss(input_):\n","    mask = input_.ge(0.000001)\n","    mask_out = torch.masked_select(input_, mask)\n","    entropy = -(torch.sum(mask_out * torch.log(mask_out)))\n","    return entropy / float(input_.size(0))\n","\n","def focal_binary_cross_entropy(logits, targets, gamma=2):\n","    num_label = targets.shape[1]\n","    l = logits.reshape(-1)\n","    t = targets.reshape(-1)\n","    p = torch.sigmoid(l)\n","    p = torch.where(t >= 0.5, p, 1-p)\n","    logp = - torch.log(torch.clamp(p, 1e-4, 1-1e-4))\n","    loss = logp*((1-p)**gamma)\n","    loss = num_label*loss.mean()\n","    return loss"],"metadata":{"id":"zKy23cw1wHB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional, Sequence\n","\n","import torch\n","from torch import Tensor\n","from torch import nn\n","from torch.nn import functional as F\n","\n","\n","class FocalLoss(nn.Module):\n","    \"\"\" Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n","    It is essentially an enhancement to cross entropy loss and is\n","    useful for classification tasks when there is a large class imbalance.\n","    x is expected to contain raw, unnormalized scores for each class.\n","    y is expected to contain class labels.\n","    Shape:\n","        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n","        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 alpha: Optional[Tensor] = None,\n","                 gamma: float = 0.,\n","                 reduction: str = 'mean',\n","                 ignore_index: int = -100):\n","        \"\"\"Constructor.\n","        Args:\n","            alpha (Tensor, optional): Weights for each class. Defaults to None.\n","            gamma (float, optional): A constant, as described in the paper.\n","                Defaults to 0.\n","            reduction (str, optional): 'mean', 'sum' or 'none'.\n","                Defaults to 'mean'.\n","            ignore_index (int, optional): class label to ignore.\n","                Defaults to -100.\n","        \"\"\"\n","        if reduction not in ('mean', 'sum', 'none'):\n","            raise ValueError(\n","                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n","\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.ignore_index = ignore_index\n","        self.reduction = reduction\n","\n","        self.nll_loss = nn.NLLLoss(\n","            weight=alpha, reduction='none', ignore_index=ignore_index)\n","\n","    def __repr__(self):\n","        arg_keys = ['alpha', 'gamma', 'ignore_index', 'reduction']\n","        arg_vals = [self.__dict__[k] for k in arg_keys]\n","        arg_strs = [f'{k}={v}' for k, v in zip(arg_keys, arg_vals)]\n","        arg_str = ', '.join(arg_strs)\n","        return f'{type(self).__name__}({arg_str})'\n","\n","    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n","        if x.ndim > 2:\n","            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n","            c = x.shape[1]\n","            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n","            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n","            y = y.view(-1)\n","\n","        unignored_mask = y != self.ignore_index\n","        y = y[unignored_mask]\n","        if len(y) == 0:\n","            return torch.tensor(0.)\n","        x = x[unignored_mask]\n","\n","        # compute weighted cross entropy term: -alpha * log(pt)\n","        # (alpha is already part of self.nll_loss)\n","        log_p = F.log_softmax(x, dim=-1)\n","        ce = self.nll_loss(log_p, y)\n","\n","        # get true class column from each row\n","        all_rows = torch.arange(len(x))\n","        log_pt = log_p[all_rows, y]\n","\n","        # compute focal term: (1 - pt)^gamma\n","        pt = log_pt.exp()\n","        focal_term = (1 - pt)**self.gamma\n","\n","        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n","        loss = focal_term * ce\n","\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","\n","        return loss\n","\n","\n","def focal_loss(alpha: Optional[Sequence] = None,\n","               gamma: float = 0.,\n","               reduction: str = 'mean',\n","               ignore_index: int = -100,\n","               device='cuda',\n","               dtype=torch.float32) -> FocalLoss:\n","    \"\"\"Factory function for FocalLoss.\n","    Args:\n","        alpha (Sequence, optional): Weights for each class. Will be converted\n","            to a Tensor if not None. Defaults to None.\n","        gamma (float, optional): A constant, as described in the paper.\n","            Defaults to 0.\n","        reduction (str, optional): 'mean', 'sum' or 'none'.\n","            Defaults to 'mean'.\n","        ignore_index (int, optional): class label to ignore.\n","            Defaults to -100.\n","        device (str, optional): Device to move alpha to. Defaults to 'cpu'.\n","        dtype (torch.dtype, optional): dtype to cast alpha to.\n","            Defaults to torch.float32.\n","    Returns:\n","        A FocalLoss object\n","    \"\"\"\n","    if alpha is not None:\n","        if not isinstance(alpha, Tensor):\n","            alpha = torch.tensor(alpha)\n","        alpha = alpha.to(device=device, dtype=dtype)\n","\n","    fl = FocalLoss(\n","        alpha=alpha,\n","        gamma=gamma,\n","        reduction=reduction,\n","        ignore_index=ignore_index)\n","    return fl"],"metadata":{"id":"dG5x6Ck0nOh_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"fvByMHwKuI4d"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","from transformers import AutoModel\n","import torch.nn.functional as F\n","\n","def init_weights(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv2d') != -1 or classname.find('ConvTranspose2d') != -1:\n","        nn.init.kaiming_uniform_(m.weight)\n","        nn.init.zeros_(m.bias)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight, 1.0, 0.02)\n","        nn.init.zeros_(m.bias)\n","    elif classname.find('Linear') != -1:\n","        nn.init.xavier_normal_(m.weight)\n","        if m.bias is not None:\n","            nn.init.zeros_(m.bias)\n","\n","\n","class AttentionWithContext(nn.Module):\n","    def __init__(self, hidden_dim):\n","        super(AttentionWithContext, self).__init__()\n","\n","        self.attn = nn.Linear(hidden_dim, hidden_dim)\n","        self.contx = nn.Linear(hidden_dim, 1, bias=False)\n","        #self.apply(init_weights)\n","    def forward(self, inp):\n","        u = torch.tanh_(self.attn(inp))\n","        a = F.softmax(self.contx(u))\n","        s = (a * inp).sum(1)\n","        return s\n","\n","\n","class TransformerLayer(nn.Module):\n","    def __init__(self,\n","                 pretrained_path='aubmindlab/bert-base-arabert'):\n","        super(TransformerLayer, self).__init__()\n","\n","        \n","        self.transformer = AutoModel.from_pretrained(pretrained_path, output_hidden_states=True)\n","\n","\n","    def forward(self, input_ids=None, attention_mask=None):\n","        outputs = self.transformer(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","        )\n","        #(output_last_layer, pooled_cls, (output_layers))\n","        #output[0] (8, seqlen=64, 768) cls [8, 768] ( 12 (8, seqlen=64, 768))\n","\n","        return outputs\n","\n","    def output_num(self):\n","        return self.transformer.config.hidden_size\n","\n","class ATTClassifier(nn.Module):\n","    def __init__(self, in_feature, class_num=1, dropout_prob=0.2):\n","        super(ATTClassifier, self).__init__()\n","        self.attention = AttentionWithContext(in_feature)\n","\n","        self.Classifier = nn.Sequential(\n","            nn.Linear(2 * in_feature, 512),\n","            nn.Dropout(dropout_prob),\n","            nn.ReLU(),\n","            nn.Linear(512, class_num)\n","        )\n","\n","        self.apply(init_weights)\n","\n","    def forward(self, x):\n","        att = self.attention(x[0]) #(X[0] (bs, seqlenght, embedD) att = \\sum_i alpha_i x[0][i]\n","\n","        xx = torch.cat([att, x[1]], 1)\n","\n","        out = self.Classifier(xx)\n","        return out\n","class Attention(nn.Module):\n","    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","        \n","        self.supports_masking = True\n","\n","        self.bias = bias\n","        self.feature_dim = feature_dim\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        \n","        weight = torch.zeros(feature_dim, 1)\n","        nn.init.kaiming_uniform_(weight)\n","        self.weight = nn.Parameter(weight)\n","        \n","        if bias:\n","            self.b = nn.Parameter(torch.zeros(step_dim))\n","        \n","    def forward(self, x, mask=None):\n","        feature_dim = self.feature_dim \n","        step_dim = self.step_dim\n","\n","        eij = torch.mm(\n","            x.contiguous().view(-1, feature_dim), \n","            self.weight\n","        ).view(-1, step_dim)\n","        \n","        if self.bias:\n","            eij = eij + self.b\n","            \n","        eij = torch.tanh(eij)\n","        a = torch.exp(eij)\n","        \n","        if mask is not None:\n","            a = a * mask\n","\n","        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n","\n","        weighted_input = x * torch.unsqueeze(a, -1)\n","        return torch.sum(weighted_input, 1)\n","\n","class NADIModel(nn.Module):\n","  def __init__(self, pretrained_path='aubmindlab/bert-base-arabert',in_feature=768, class_num=18, dropout_prob=0.2):\n","        super(NADIModel, self).__init__()\n","        self.base_model=TransformerLayer(pretrained_path).to('cuda')\n","        self.att=Attention(self.base_model.output_num(), 128).to('cuda')\n","        self.classifier=nn.Linear(self.base_model.output_num(), class_num)\n","  def forward(self, ids,mask):\n","    output=self.base_model(ids,mask)\n","    output=self.att(output.last_hidden_state)\n","    output=self.classifier(output)\n","    # output=torch.softmax(output, dim=1)\n","    return output\n"," "],"metadata":{"id":"FW53GnvRuJ6J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train, Validation"],"metadata":{"id":"SYQWLGzVyqt_"}},{"cell_type":"code","source":["class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n","    \"\"\"\n","    Samples elements randomly from a given list of indices for imbalanced dataset\n","    Arguments:\n","        indices (list, optional): a list of indices\n","        num_samples (int, optional): number of samples to draw\n","    \"\"\"\n","\n","    def __init__(self, dataset, indices=None, num_samples=None):\n","        # if indices is not provided,\n","        # all elements in the dataset will be considered\n","        self.indices = list(range(len(dataset['#3_label']))) \\\n","            if indices is None else indices\n","\n","        # if num_samples is not provided,\n","        # draw `len(indices)` samples in each iteration\n","        self.num_samples = len(self.indices) \\\n","            if num_samples is None else num_samples\n","\n","        # distribution of classes in the dataset\n","        label_to_count = {}\n","        for idx in self.indices:\n","            label = self._get_label(dataset, idx)\n","            if label in label_to_count:\n","                label_to_count[label] += 1\n","            else:\n","                label_to_count[label] = 1\n","\n","        # weight for each sample\n","        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n","        self.weights = torch.DoubleTensor(weights)\n","\n","    def _get_label(self, dataset, id_):\n","        return dataset['#3_label'][id_]\n","\n","    def __iter__(self):\n","        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n","\n","    def __len__(self):\n","        return self.num_samples"],"metadata":{"id":"pjYrf5IerGh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def criterion(outputs1,  targets):\n","\n","    criterion = F1_Loss()\n","    criterion_2 = FocalLoss()\n","    loss = 0.5*criterion(outputs1, targets)+0.5*criterion_2(outputs1, targets)\n","    return loss"],"metadata":{"id":"ZWP3677hqMr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        \n","        text_ids = data['text_ids'].to(device, dtype = torch.long)\n","        text_mask = data['text_mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","        \n","        batch_size = text_ids.size(0)\n","        # print(targets)\n","\n","        outputs = model(text_ids, text_mask)\n","        # print(outputs.shape)\n","        \n","        # print(outputs.shape)\n","\n","        \n","        loss = criterion(outputs, targets)\n","        loss = loss / CONFIG['n_accumulate']\n","        loss.backward()\n","    \n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"],"metadata":{"id":"ltIB44KZyxPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        \n","        text_ids = data['text_ids'].to(device, dtype = torch.long)\n","        text_mask = data['text_mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","        \n","        batch_size = text_ids.size(0)\n","\n","        outputs = model(text_ids, text_mask)\n","        # outputs = outputs.argmax(dim=1)\n","        \n","        loss = criterion(outputs, targets)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])   \n","    \n","    gc.collect()\n","    \n","    return epoch_loss"],"metadata":{"id":"U5Ro64pIy4HN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_training(model, optimizer, scheduler, device, num_epochs, fold,train_loader, valid_loader):\n","    # To automatically log gradients\n","    \n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","    \n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","    history = defaultdict(list)\n","    \n","    for epoch in range(1, num_epochs + 1): \n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n","                                           dataloader=train_loader, \n","                                           device=CONFIG['device'], epoch=epoch)\n","        \n","        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n","                                         epoch=epoch)\n","    \n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Valid Loss'].append(val_epoch_loss)\n","        \n","       \n","        \n","        # deep copy the model\n","        if val_epoch_loss <= best_epoch_loss:\n","            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n","            best_epoch_loss = val_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = f\"/content/drive/MyDrive/wanlp/NADI/Saved_Models/AraT5-tweet-base/Loss-Fold-{fold}.bin\"\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(\"Model Saved\")\n","            \n","        print()\n","    \n","    end = time.time()\n","    time_elapsed = end - start\n","    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n","    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n","    \n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, history"],"metadata":{"id":"HpH2EB0snbV0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fetch_scheduler(optimizer):\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == None:\n","        return None\n","        \n","    return scheduler"],"metadata":{"id":"JxT6JHg0nogC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_loaders(train,fold):\n","    df_train = train[train.kfold != fold].reset_index(drop=True)\n","    df_valid = train[train.kfold == fold].reset_index(drop=True)\n","    # print(len(df_valid))\n","    sampler = ImbalancedDatasetSampler(df_train)\n","    \n","    train_dataset = TrainDataset(df_train, tokenizer=tokenizer, max_length=CONFIG['max_length'])\n","    valid_dataset = TrainDataset(df_valid, tokenizer=tokenizer, max_length=CONFIG['max_length'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n","                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n","                              num_workers=2, shuffle=False, pin_memory=True)\n","    \n","    return train_loader, valid_loader"],"metadata":{"id":"x-x9oUAsnqqy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"T-MsRHzBnZX8"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ih8htg1LoRZC","executionInfo":{"status":"ok","timestamp":1661622506934,"user_tz":-120,"elapsed":35827,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"outputId":"706b3eee-7124-4e64-fd13-56bed01b5adc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ,jmnbv"],"metadata":{"id":"yeq4g6QBasWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv('/content/drive/MyDrive/wanlp/Datasets/NADI2022-Train/NADI2022-Train/Subtask1/NADI2022_Subtask1_TRAIN.tsv', sep='\\t', lineterminator='\\n')\n","valid = pd.read_csv('/content/drive/MyDrive/wanlp/Datasets/NADI2022-Train/NADI2022-Train/Subtask1/NADI2022_Subtask1_DEV.tsv', sep='\\t', lineterminator='\\n')"],"metadata":{"id":"5dHag8YTn7jE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ZLZqgBrJoyaa","executionInfo":{"status":"ok","timestamp":1661622512069,"user_tz":-120,"elapsed":26,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"outputId":"7d8e2259-986c-43d1-a448-4ab51e55bee1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         #1_id                                         #2_content #3_label\n","0  TRAIN_15711                         الطرحة في 61 النفر 10 جنيه    yemen\n","1   TRAIN_2257  كله ولا يطالبوا بارض فدك الله ياخدهم الله يعجل...  lebanon\n","2   TRAIN_5618  ' لما اطلقتو تلك التغريدة وقتها كان في واحد سع...  algeria\n","3   TRAIN_7284                                      بجكولى بى خير     iraq\n","4  TRAIN_15841                              يعم القمر براحه علينا    egypt"],"text/html":["\n","  <div id=\"df-21096f2e-31a8-4518-8644-c168fa4f0698\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>#1_id</th>\n","      <th>#2_content</th>\n","      <th>#3_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_15711</td>\n","      <td>الطرحة في 61 النفر 10 جنيه</td>\n","      <td>yemen</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_2257</td>\n","      <td>كله ولا يطالبوا بارض فدك الله ياخدهم الله يعجل...</td>\n","      <td>lebanon</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_5618</td>\n","      <td>' لما اطلقتو تلك التغريدة وقتها كان في واحد سع...</td>\n","      <td>algeria</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_7284</td>\n","      <td>بجكولى بى خير</td>\n","      <td>iraq</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_15841</td>\n","      <td>يعم القمر براحه علينا</td>\n","      <td>egypt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21096f2e-31a8-4518-8644-c168fa4f0698')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-21096f2e-31a8-4518-8644-c168fa4f0698 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-21096f2e-31a8-4518-8644-c168fa4f0698');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["len(train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gB9D4twgo0bI","executionInfo":{"status":"ok","timestamp":1661622512070,"user_tz":-120,"elapsed":15,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"outputId":"8d96d1b6-8454-4ff2-d554-d9d18f4b5bb2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20398"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["train['#3_label'].nunique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYdSpBt2o2HR","executionInfo":{"status":"ok","timestamp":1661622512070,"user_tz":-120,"elapsed":13,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"outputId":"53af2060-bf5b-4155-b9c3-891daa49fe7b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["valid['#3_label'].nunique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LREmIaISpGJF","executionInfo":{"status":"ok","timestamp":1661622512071,"user_tz":-120,"elapsed":11,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"outputId":"0c24cafc-1490-4656-a3ec-a692f67a69b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["df_train=train.copy()"],"metadata":{"id":"alyqp1JApKHQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes=df_train['#3_label'].nunique()"],"metadata":{"id":"F8zmQRzrpDra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CONFIG = {\"seed\": 42,\n","          \"epochs\": 5,\n","          \"train_batch_size\": 2,\n","          \"valid_batch_size\": 4,\n","          \"max_length\": 128,\n","          \"learning_rate\": 2e-5,\n","          \"scheduler\": 'CosineAnnealingLR',\n","          \"min_lr\": 1e-8,\n","          \"T_max\": 500,\n","          \"weight_decay\": 1e-8,\n","          \"n_fold\": 5,\n","          \"n_accumulate\": 1,\n","          \"num_classes\": 18,\n","          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","          }"],"metadata":{"id":"0_HBDMdYn1Mi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer= AutoTokenizer.from_pretrained('aubmindlab/aragpt2-base')\n"],"metadata":{"id":"89VbI4nqq17L","executionInfo":{"status":"ok","timestamp":1661622530762,"user_tz":-120,"elapsed":18699,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["57fccb66f7d243ecb79246c21603a603","ed5ea7d87f61463dad6b9c5db5a0fce7","f7639348fd6947febba3e7434f234134","5e0a4acbb6e64395aa9a98d5b8681505","4bcbf766c3de41de825af00b42600c73","1920fb64701a48028f14eb55022ccf64","6353bac2f5414b68944a3b9772575e0a","ee5276ebaed0461a8d37a229a31b2379","8ddde168e42c42508d77a308b1ad62dc","b60e6760ba27427580a7a0ca2a6da3c7","f549498befdc43c9a618d0f148f1c07e","a81be2c57a2c4243ba427411330a6e8b","03c883f7589b4ddf9ad2431b9e091773","ad038048801941998def13303185bab1","4716ae0bd06942d195475e418f562f60","e7c7ef6cb46f4ad0a6f94d209de7af9d","e740db6f56de4765874980b524be5104","481f374c3fb04aca99de318ef0c10102","e1abbea96af64380aeeafb4dfc6afda2","fc67e087106d4959b95ea2056a2bb429","b1bbbcf9089c46a4b1278bb01d12c20b","ca6afcff08ec4dca81b589b57dfc4c81","add0e37764d54aad9468b39c989bab29","9fc76f085b0e4588bbd25282ec2d983d","80e18347534b4c47aae6b463bf87650a","f290dfbddd704f9cbc1bbc50800d4516","7c453fb00ac5489a851c11e72f8d78e6","d2ba4b042767405da91000fbb2d39e28","311350cf2ae04b78bcbe1c7d62d719fd","1ca94cb69271412885aaa3862e7818f3","ff5313664f904e529e66ebfe6f800f45","b2159900cdc84743a50a98ca1dc3419d","5c361df58f80483ca5813e9e4da3e3ed","e6a0950cdf144911a1927042871a17f4","66797fd1ad054ae992fe4a624cdaebd4","c07a6a760d664eb0ab2aca59bc66428a","520318c7827b46f2961eba07b98e8089","1dd9f1b258c94a8394e70fb753557da4","1249dd83cb3b451091c7b5b439f60650","92806c3935dc4e3f91fb67f6249e3bff","5c101be9f684471a97145e10478865d1","5782c97ff99645c29aeb4ccdcaa311ff","e7581ae4395043318a914702d267ecd1","e18f15c56bd94ca992c7a95e3ba64513"]},"outputId":"16f7e532-de81-4ed7-a35d-013cbfd3f8d0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57fccb66f7d243ecb79246c21603a603"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/1.85M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81be2c57a2c4243ba427411330a6e8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/1.43M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add0e37764d54aad9468b39c989bab29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a0950cdf144911a1927042871a17f4"}},"metadata":{}}]},{"cell_type":"code","source":["df_train.reset_index(inplace=True)"],"metadata":{"id":"E9sfjlh6qj6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n","\n","for fold, ( _, val_) in enumerate(skf.split(X=df_train, y=df_train['#3_label'])):\n","    df_train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","df_train[\"kfold\"] = df_train[\"kfold\"].astype(int)"],"metadata":{"id":"Dq0tSkUrntN4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train['kfold'].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_0l7FW06mgP","executionInfo":{"status":"ok","timestamp":1661622530767,"user_tz":-120,"elapsed":15,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}},"outputId":"9f11a5f4-db59-4476-bf5d-b3d65a41a7fe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 2, 3, ..., 0, 1, 2])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","df_train['#3_label'] = le.fit_transform(df_train['#3_label'].values)\n"],"metadata":{"id":"wOMg6NEVsEkU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"id":"R4qfvxfpPiOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for fold in range(3, CONFIG['n_fold']):\n","    print(f\"====== Fold: {fold} ======\")\n","\n","    \n","    # Create Dataloaders\n","    train_loader, valid_loader = prepare_loaders(df_train,fold=fold)\n","    \n","    model = NADIModel('aubmindlab/aragpt2-base')\n","    model.to(CONFIG['device'])\n","    torch.cuda.empty_cache()\n","    \n","    # Define Optimizer and Scheduler\n","    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n","    scheduler = fetch_scheduler(optimizer)\n","    \n","    model, history = run_training(model, optimizer, scheduler,\n","                                  device=CONFIG['device'],\n","                                  num_epochs=CONFIG['epochs'],\n","                                  fold=fold,train_loader=train_loader, valid_loader=valid_loader )\n","    \n","    \n","    del model, history, train_loader, valid_loader\n","    _ = gc.collect()\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2ca5a996a5124f79901e3fdef70c91b4","64041a0521f54576875a1ae61242a264","0d3c119add5043739d7d06826dd51a58","d5c47d7e4c6a41efbbedc22f70bf0447","a7410c88ab6b42e49911dc37220ae60a","4602948403a046d4a6a09c1ce0c501ad","60dc8fa56f914b49b406a3cde92db835","bb320e07681242c98052146ac750bc16","8ea6a009458946a5b781960551cbc15e","a923eea457694ccdac603de5e76aadc9","52ca27d461944a27a9b3bb89f881ebc9"]},"id":"RdoS6yH5nwWG","outputId":"acd845a1-949d-4a91-f892-f1c96064ef1f","executionInfo":{"status":"ok","timestamp":1661632284426,"user_tz":-120,"elapsed":9753672,"user":{"displayName":"Reem Mohamed","userId":"09040852339831377826"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["====== Fold: 3 ======\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/527M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca5a996a5124f79901e3fdef70c91b4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU: Tesla T4\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:39<00:00,  8.68it/s, Epoch=1, LR=1.54e-5, Train_Loss=1.63]\n","100%|██████████| 1020/1020 [00:38<00:00, 26.39it/s, Epoch=1, LR=1.54e-5, Valid_Loss=1.6]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (inf ---> 1.6038697483376505)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:33<00:00,  8.74it/s, Epoch=2, LR=5.86e-6, Train_Loss=1.39]\n","100%|██████████| 1020/1020 [00:38<00:00, 26.47it/s, Epoch=2, LR=5.86e-6, Valid_Loss=1.5]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.6038697483376505 ---> 1.4971949314626884)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:25<00:00,  8.82it/s, Epoch=3, LR=1.14e-7, Train_Loss=1.27]\n","100%|██████████| 1020/1020 [00:37<00:00, 26.87it/s, Epoch=3, LR=1.14e-7, Valid_Loss=1.43]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.4971949314626884 ---> 1.4281706038161976)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:31<00:00,  8.76it/s, Epoch=4, LR=3.44e-6, Train_Loss=1.16]\n","100%|██████████| 1020/1020 [00:38<00:00, 26.44it/s, Epoch=4, LR=3.44e-6, Valid_Loss=1.4]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.4281706038161976 ---> 1.4010424333099174)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:29<00:00,  8.77it/s, Epoch=5, LR=1.28e-5, Train_Loss=1.06]\n","100%|██████████| 1020/1020 [00:37<00:00, 26.90it/s, Epoch=5, LR=1.28e-5, Valid_Loss=1.42]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training complete in 1h 21m 20s\n","Best Loss: 1.4010\n","\n","====== Fold: 4 ======\n","[INFO] Using GPU: Tesla T4\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:22<00:00,  8.85it/s, Epoch=1, LR=1.54e-5, Train_Loss=1.58]\n","100%|██████████| 1020/1020 [00:37<00:00, 26.87it/s, Epoch=1, LR=1.54e-5, Valid_Loss=1.57]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (inf ---> 1.5725507953933244)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:21<00:00,  8.86it/s, Epoch=2, LR=5.86e-6, Train_Loss=1.39]\n","100%|██████████| 1020/1020 [00:38<00:00, 26.62it/s, Epoch=2, LR=5.86e-6, Valid_Loss=1.47]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.5725507953933244 ---> 1.467964602323337)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:22<00:00,  8.85it/s, Epoch=3, LR=1.14e-7, Train_Loss=1.26]\n","100%|██████████| 1020/1020 [00:37<00:00, 26.90it/s, Epoch=3, LR=1.14e-7, Valid_Loss=1.44]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.467964602323337 ---> 1.4399413577362905)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:31<00:00,  8.76it/s, Epoch=4, LR=3.44e-6, Train_Loss=1.14]\n","100%|██████████| 1020/1020 [00:38<00:00, 26.66it/s, Epoch=4, LR=3.44e-6, Valid_Loss=1.44]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Improved (1.4399413577362905 ---> 1.4363803979110765)\n","Model Saved\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8159/8159 [15:27<00:00,  8.80it/s, Epoch=5, LR=1.28e-5, Train_Loss=1.03]\n","100%|██████████| 1020/1020 [00:37<00:00, 26.96it/s, Epoch=5, LR=1.28e-5, Valid_Loss=1.45]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training complete in 1h 20m 27s\n","Best Loss: 1.4364\n","\n"]}]}]}