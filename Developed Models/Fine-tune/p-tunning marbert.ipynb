{"cells":[{"cell_type":"code","source":["!pip install sentencepiece\n","!pip  install transformers\n","!pip install pytorch-ignite\n","!pip install datasets\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIbuS3X-Tb9X","executionInfo":{"status":"ok","timestamp":1662483364656,"user_tz":-120,"elapsed":32874,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"62ebc508-d0e4-4a76-875b-be5587f2d657"},"id":"PIbuS3X-Tb9X","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 27.9 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 9.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 50.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 52.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.10-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 33.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n","Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.4.10\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 31.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 68.8 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 67.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 72.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]}]},{"cell_type":"code","execution_count":null,"id":"5aa5b66c","metadata":{"id":"5aa5b66c"},"outputs":[],"source":["import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch\n","from transformers import AutoModel\n","import torch.nn.functional as F\n","from sklearn.metrics import f1_score, accuracy_score, classification_report\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","# Any results you write to the current directory are saved as output.\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","from transformers import BertTokenizer,BertModel\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,Dataset\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from torch.optim import AdamW\n","from tqdm import tqdm\n","from argparse import ArgumentParser\n","from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n","from ignite.metrics import Accuracy, Loss\n","from ignite.engine.engine import Engine, State, Events\n","from ignite.handlers import EarlyStopping\n","from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n","from ignite.utils import convert_tensor\n","from torch.optim.lr_scheduler import ExponentialLR\n","import warnings  \n","warnings.filterwarnings('ignore')\n","import gc\n","import copy\n","import time\n","import random\n","import string\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Pytorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Utils\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, KFold\n","from transformers import AutoTokenizer, AutoModel, AdamW\n","import random\n","import os\n","from urllib import request\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n","\n","from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n","from transformers.data.processors import SingleSentenceClassificationProcessor\n","from transformers import Trainer , TrainingArguments\n","from transformers.trainer_utils import EvaluationStrategy\n","from transformers.data.processors.utils import InputFeatures\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","id":"ee83285d","metadata":{"id":"ee83285d"},"source":["# Helper Function"]},{"cell_type":"code","execution_count":null,"id":"6a5a84e1","metadata":{"id":"6a5a84e1"},"outputs":[],"source":["# Define a dataset class for prompted BERT fine tuning\n","# The dataset takes in query and passage, and then construct a training sample as:  <prompt> + [MASK] + <text>, returning the position of the mask\n","# It also performs padding and stores the labels\n","class BERTPromptDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataset, labels, tokenizer, prompt=\"اللكنه هي؟\", max_length=512):\n","        self.text=dataset['text']\n","        self.labels=labels\n","        # Construct the input sentence\n","#         input_sentences = [\"{} {} {}\".format(prompt, tokenizer.mask_token, text) for _, (text) in dataset.iterrows()]\n","        \n","#         # Encode and store\n","#         encodings_dict = tokenizer.batch_encode_plus(input_sentences, truncation=True, max_length=max_length, padding=\"max_length\")\n","#         self.input_ids = encodings_dict['input_ids']\n","#         self.attn_masks = encodings_dict['attention_mask']\n","#         self.labels = labels\n","\n","#         # Calculate the position of the mask using self.input_ids\n","#         mask_id = tokenizer.encode(tokenizer.mask_token)[1] # 103\n","#         self.mask_pos = [sent_ids.index(mask_id) for sent_ids in self.input_ids]\n","        \n","        \n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, idx):\n","        return_dict = {\"text\": self.text[idx],                       \n","                       \"labels\": torch.tensor(self.labels[idx]).float()} \n","        return return_dict"]},{"cell_type":"code","source":["class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n","    \"\"\"\n","    Samples elements randomly from a given list of indices for imbalanced dataset\n","    Arguments:\n","        indices (list, optional): a list of indices\n","        num_samples (int, optional): number of samples to draw\n","    \"\"\"\n","\n","    def __init__(self, dataset, indices=None, num_samples=None):\n","        # if indices is not provided,\n","        # all elements in the dataset will be considered\n","        self.indices = list(range(len(dataset['label']))) \\\n","            if indices is None else indices\n","\n","        # if num_samples is not provided,\n","        # draw `len(indices)` samples in each iteration\n","        self.num_samples = len(self.indices) \\\n","            if num_samples is None else num_samples\n","\n","        # distribution of classes in the dataset\n","        label_to_count = {}\n","        for idx in self.indices:\n","            label = self._get_label(dataset, idx)\n","            if label in label_to_count:\n","                label_to_count[label] += 1\n","            else:\n","                label_to_count[label] = 1\n","\n","        # weight for each sample\n","        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n","        self.weights = torch.DoubleTensor(weights)\n","\n","    def _get_label(self, dataset, id_):\n","        return dataset['label'][id_]\n","\n","    def __iter__(self):\n","        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n","\n","    def __len__(self):\n","        return self.num_samples"],"metadata":{"id":"hXrPQmCd8YKS"},"id":"hXrPQmCd8YKS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","        \n","        self.supports_masking = True\n","\n","        self.bias = bias\n","        self.feature_dim = feature_dim\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        \n","        weight = torch.zeros(feature_dim, 1)\n","        nn.init.kaiming_uniform_(weight)\n","        self.weight = nn.Parameter(weight)\n","        \n","        if bias:\n","            self.b = nn.Parameter(torch.zeros(step_dim))\n","        \n","    def forward(self, x, mask=None):\n","        feature_dim = self.feature_dim \n","        step_dim = self.step_dim\n","\n","        eij = torch.mm(\n","            x.contiguous().view(-1, feature_dim), \n","            self.weight\n","        ).view(-1, step_dim)\n","        \n","        if self.bias:\n","            eij = eij + self.b\n","            \n","        eij = torch.tanh(eij)\n","        a = torch.exp(eij)\n","        \n","        if mask is not None:\n","            a = a * mask\n","\n","        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n","\n","        weighted_input = x * torch.unsqueeze(a, -1)\n","        return torch.sum(weighted_input, 1)"],"metadata":{"id":"CeRJphhR_KKl"},"id":"CeRJphhR_KKl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class WeightedLayerPooling(nn.Module):\n","    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights=None):\n","        super(WeightedLayerPooling, self).__init__()\n","        self.layer_start = layer_start\n","        self.num_hidden_layers = num_hidden_layers\n","        self.layer_weights = layer_weights if layer_weights is not None \\\n","            else nn.Parameter(\n","            torch.tensor([1] * (num_hidden_layers + 1 - layer_start), dtype=torch.float)\n","        )\n","\n","    def forward(self, all_hidden_states):\n","        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n","        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n","        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n","        return weighted_average"],"metadata":{"id":"mVCcOQJa9Yar"},"id":"mVCcOQJa9Yar","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ae89b674","metadata":{"id":"ae89b674"},"outputs":[],"source":["# # Class that expects a prompted input from the BERTPromptDataset\n","# # Takes the input, forward propagates it through BERT and concatenates the output at the [MASK] and [CLS] token to get a representation of the text\n","# # This is then passed to a linear head to perform binary classification for how relevant it is\n","# class BERTPrompt(torch.nn.Module):\n","#     def __init__(self, bert, tokenizer):\n","#         super().__init__()\n","#         self.bert = bert.cuda()\n","#         self.tokenizer = tokenizer\n","#         self.linear = torch.nn.Linear(768*2, 3).cuda()\n","#         self.act = torch.nn.Softmax()\n","        \n","#     # input_dict is obtained through indexing the dataset e.g. dataset[0:10]\n","#     def forward(self, input_ids,attention_mask,mask_pos ):\n","#         output = self.bert(input_ids,attention_mask)[0] # output is of shape [10, 256, 768]\n","#         cls_out = output[:, 0, :]\n","#         mask_out = output[torch.arange(cls_out.shape[0]), mask_pos, :] # indexing like [[0, 1], [13, 14]] will select items [[0, 13], [1, 14]]\n","        \n","#         representation = torch.cat([cls_out, mask_out], dim=1)\n","#         logit = self.linear(representation)\n","#         return logit\n","    \n","# #     # return the logit with sigmoid activation applied\n","# #     def predict(self, input_dict):\n","# #         return self.forward(input_dict)"]},{"cell_type":"code","execution_count":null,"id":"b49ce0f3","metadata":{"id":"b49ce0f3"},"outputs":[],"source":["# Class Plan:\n","# take in the length of the prompt\n","# create an embedding layer for that many tokens\n","# create an LSTM and MLP to process the prompt \n","# How to feed the embedding to BERT\n","    # Get the embedding layer using https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#transformers.BertModel.get_input_embeddings \n","    # Then directly pass embedding to BERT using self.bert(input_embeds=, attention_mask=)\n","# add prompting logic to the tokenizer function\n","    # it needs to first pass all tokens through LSTM and MLP\n","    # then add them into the sentence as needed\n","class BERTPrompt(torch.nn.Module):\n","    def __init__(self, bert, tokenizer, max_length=512, prompt_length=5):\n","        super().__init__()\n","        self.hidden_size = 768\n","        self.max_length = max_length\n","        self.prompt_length = prompt_length\n","        self.config = AutoConfig.from_pretrained('aubmindlab/bert-base-arabertv02-twitter')\n","        self.weighted_pooler = WeightedLayerPooling(num_hidden_layers=self.config.num_hidden_layers, layer_start=4)\n","        \n","        self.bert = bert.cuda()\n","        self.tokenizer = tokenizer\n","        self.bert_embedding = self.bert.get_input_embeddings()\n","        self.att=Attention(768, 512).to('cuda')\n","        self.linear = torch.nn.Linear(self.hidden_size, 18).cuda()\n","        # self.act = torch.nn.Sigmoid() \n","        \n","        # p tuning modules\n","        self.prompt_embedding = torch.nn.Embedding(prompt_length, self.hidden_size).cuda()\n","        self.lstm_head = torch.nn.LSTM(input_size=self.hidden_size, hidden_size=int(self.hidden_size/2),\n","            num_layers=2, bidirectional=True, batch_first=True).cuda() # takes (batch_size, sequence length, hidden_size)\n","        self.mlp_head = torch.nn.Sequential(torch.nn.Linear(self.hidden_size, self.hidden_size),\n","                                            torch.nn.ReLU(),\n","                                            torch.nn.Linear(self.hidden_size, self.hidden_size)).cuda()\n","        \n","    # calls the tokenize function to get input embeddings, then passes them through bert\n","    def forward(self, input_sents):\n","        embeds = torch.zeros(len(input_sents), self.max_length, self.hidden_size).cuda()\n","        att_mask = torch.zeros(len(input_sents), self.max_length).cuda().long()\n","        for i, sent in enumerate(input_sents):\n","            embeds[i, :, :], att_mask[i, :] = self.tokenize(sent)\n","        \n","        output = self.bert(inputs_embeds=embeds, attention_mask=att_mask)\n","        all_hidden_states = torch.stack(output.hidden_states)\n","        weighted_pooling_embeddings = self.weighted_pooler(all_hidden_states)\n","        output=self.att(weighted_pooling_embeddings)\n","        # cls_out = output[:, 0, :]\n","        logits = self.linear(output)\n","        return logits\n","    \n","    # a tokenize function that embeds the sentence adds the prompt to the end and returns token embeddings along with attention mask\n","    def tokenize(self, input_sent,prompt='اللكنه هي؟'):\n","        # generate prompt tokens from embedding\n","        self.prompt_length=len(tokenizer.encode(prompt))\n","        prompt_tokens = self.prompt_embedding(torch.arange(self.prompt_length).cuda())\n","        prompt_tokens = torch.unsqueeze(prompt_tokens, 0) # add a batch dimension\n","        prompt_tokens, _ = self.lstm_head(prompt_tokens)\n","        prompt_tokens = self.mlp_head(prompt_tokens)[0]\n","        \n","        # Encode the input_sentence\n","        encoding_dict = self.tokenizer.encode_plus(input_sent, truncation=True, max_length=self.max_length, padding=\"max_length\")        \n","#         input_ids = encoding_dict[\"input_ids\"]\n","#         mask_id = tokenizer.encode(tokenizer.mask_token)[1] # 103\n","        sep_pos = len(input_sent)\n","        \n","        \n","        \n","#         sep_pos = encoding_dict[\"input_ids\"].index(102) # the location of the [SEP] token is at the end of the input\n","        token_embeds = self.bert_embedding(torch.tensor(encoding_dict[\"input_ids\"]).cuda())\n","        \n","        # Add the prompt tokens to the end and modify the att_mask to include the prompt\n","        start_prompt_pos = min(sep_pos, self.max_length - self.prompt_length - 1) # if the sentence is truncutated we must further truncate it to fit in the prompt\n","        end_prompt_pos = start_prompt_pos + self.prompt_length + 1\n","        token_embeds[start_prompt_pos:end_prompt_pos, :] = torch.cat([prompt_tokens, token_embeds[sep_pos:sep_pos+1, :]], dim=0)\n","        att_mask = encoding_dict[\"attention_mask\"]\n","        att_mask[start_prompt_pos:end_prompt_pos] = [1]*(self.prompt_length+1)\n","        att_mask = torch.tensor(att_mask).cuda()\n","        \n","        return token_embeds, att_mask"]},{"cell_type":"code","execution_count":null,"id":"a8e9f546","metadata":{"id":"a8e9f546"},"outputs":[],"source":["from typing import Optional, Sequence\n","\n","import torch\n","from torch import Tensor\n","from torch import nn\n","from torch.nn import functional as F\n","\n","\n","class FocalLoss(nn.Module):\n","    \"\"\" Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n","    It is essentially an enhancement to cross entropy loss and is\n","    useful for classification tasks when there is a large class imbalance.\n","    x is expected to contain raw, unnormalized scores for each class.\n","    y is expected to contain class labels.\n","    Shape:\n","        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n","        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 alpha: Optional[Tensor] = None,\n","                 gamma: float = 0.,\n","                 reduction: str = 'mean',\n","                 ignore_index: int = -100):\n","        \"\"\"Constructor.\n","        Args:\n","            alpha (Tensor, optional): Weights for each class. Defaults to None.\n","            gamma (float, optional): A constant, as described in the paper.\n","                Defaults to 0.\n","            reduction (str, optional): 'mean', 'sum' or 'none'.\n","                Defaults to 'mean'.\n","            ignore_index (int, optional): class label to ignore.\n","                Defaults to -100.\n","        \"\"\"\n","        if reduction not in ('mean', 'sum', 'none'):\n","            raise ValueError(\n","                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n","\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.ignore_index = ignore_index\n","        self.reduction = reduction\n","\n","        self.nll_loss = nn.NLLLoss(\n","            weight=alpha, reduction='none', ignore_index=ignore_index)\n","\n","    def __repr__(self):\n","        arg_keys = ['alpha', 'gamma', 'ignore_index', 'reduction']\n","        arg_vals = [self.__dict__[k] for k in arg_keys]\n","        arg_strs = [f'{k}={v}' for k, v in zip(arg_keys, arg_vals)]\n","        arg_str = ', '.join(arg_strs)\n","        return f'{type(self).__name__}({arg_str})'\n","\n","    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n","        if x.ndim > 2:\n","            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n","            c = x.shape[1]\n","            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n","            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n","            y = y.view(-1)\n","\n","        unignored_mask = y != self.ignore_index\n","        y = y[unignored_mask]\n","        if len(y) == 0:\n","            return torch.tensor(0.)\n","        x = x[unignored_mask]\n","\n","        # compute weighted cross entropy term: -alpha * log(pt)\n","        # (alpha is already part of self.nll_loss)\n","        log_p = F.log_softmax(x, dim=-1)\n","        ce = self.nll_loss(log_p, y)\n","\n","        # get true class column from each row\n","        all_rows = torch.arange(len(x))\n","        log_pt = log_p[all_rows, y]\n","\n","        # compute focal term: (1 - pt)^gamma\n","        pt = log_pt.exp()\n","        focal_term = (1 - pt)**self.gamma\n","\n","        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n","        loss = focal_term * ce\n","\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","\n","        return loss\n","\n","\n","def focal_loss(alpha: Optional[Sequence] = None,\n","               gamma: float = 0.,\n","               reduction: str = 'mean',\n","               ignore_index: int = -100,\n","               device='cuda',\n","               dtype=torch.float32) -> FocalLoss:\n","    \"\"\"Factory function for FocalLoss.\n","    Args:\n","        alpha (Sequence, optional): Weights for each class. Will be converted\n","            to a Tensor if not None. Defaults to None.\n","        gamma (float, optional): A constant, as described in the paper.\n","            Defaults to 0.\n","        reduction (str, optional): 'mean', 'sum' or 'none'.\n","            Defaults to 'mean'.\n","        ignore_index (int, optional): class label to ignore.\n","            Defaults to -100.\n","        device (str, optional): Device to move alpha to. Defaults to 'cpu'.\n","        dtype (torch.dtype, optional): dtype to cast alpha to.\n","            Defaults to torch.float32.\n","    Returns:\n","        A FocalLoss object\n","    \"\"\"\n","    if alpha is not None:\n","        if not isinstance(alpha, Tensor):\n","            alpha = torch.tensor(alpha)\n","        alpha = alpha.to(device=device, dtype=dtype)\n","\n","    fl = FocalLoss(\n","        alpha=alpha,\n","        gamma=gamma,\n","        reduction=reduction,\n","        ignore_index=ignore_index)\n","    return fl"]},{"cell_type":"code","execution_count":null,"id":"fd1a573b","metadata":{"id":"fd1a573b"},"outputs":[],"source":["class F1_Loss(nn.Module):\n","    '''Calculate F1 score. Can work with gpu tensors\n","    \n","    The original implmentation is written by Michal Haltuf on Kaggle.\n","    \n","    Returns\n","    -------\n","    torch.Tensor\n","        `ndim` == 1. epsilon <= val <= 1\n","    \n","    Reference\n","    ---------\n","    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n","    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n","    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n","    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n","    '''\n","    def __init__(self, epsilon=1e-7):\n","        super().__init__()\n","        self.epsilon = epsilon\n","        \n","    def forward(self, y_pred, y_true,):\n","        # assert y_pred.ndim == 2\n","        # assert y_true.ndim == 1\n","        # print(y_pred.shape)\n","        # print(y_true.shape)\n","        # y_pred[y_pred<0.5]=0\n","        # y_pred[y_pred>=0.5]=0\n","\n","\n","        \n","        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 3).to(torch.float32)\n","        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n","        \n","        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n","        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n","        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n","        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n","        f1=f1.detach()\n","        # print(f1.shape)\n","        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n","        # y_true=y_true.reshape((y_true.shape[0], 1))\n","\n","        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n","        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n","\n","\n","        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n","        # print(y_pred)\n","        # print(y_true_one_hot)\n","        CE =torch.nn.CrossEntropyLoss(weight=( 1 - f1))(y_pred, y_true)\n","        # loss = ( 1 - f1)  * CE\n","        return  CE.mean()"]},{"cell_type":"code","execution_count":null,"id":"d34272c0","metadata":{"id":"d34272c0"},"outputs":[],"source":["def criterion(outputs1,  targets):\n","\n","    criterion = FocalLoss()\n","    loss = criterion(outputs1, targets)\n","    return loss"]},{"cell_type":"code","execution_count":null,"id":"050781e1","metadata":{"id":"050781e1"},"outputs":[],"source":["def run_training(model, optimizer, scheduler, device, num_epochs, train_loader, valid_loader):\n","    # To automatically log gradients\n","    \n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","    \n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = 0\n","    history = defaultdict(list)\n","    \n","    for epoch in range(1, num_epochs + 1): \n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n","                                           dataloader=train_loader, \n","                                           device=CONFIG['device'], epoch=epoch)\n","        \n","        val_epoch_loss,f1_score = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n","                                         epoch=epoch)\n","    \n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Valid Loss'].append(val_epoch_loss)\n","        \n","       \n","        \n","        # deep copy the model\n","        if f1_score >= best_epoch_loss:\n","            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {f1_score})\")\n","            best_epoch_loss = f1_score\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = f\"/content/drive/MyDrive/wanlp/NADI/Saved_Models/marbert_prompt/Loss_arabert_wsampler.bin\"\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(\"Model Saved\")\n","            \n","        print()\n","    \n","    end = time.time()\n","    time_elapsed = end - start\n","    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n","    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n","    \n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, history"]},{"cell_type":"code","execution_count":null,"id":"14c9ffd1","metadata":{"id":"14c9ffd1"},"outputs":[],"source":["def fetch_scheduler(optimizer):\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == None:\n","        return None\n","        \n","    return scheduler"]},{"cell_type":"code","execution_count":null,"id":"b770511e","metadata":{"id":"b770511e"},"outputs":[],"source":["def prepare_loaders(train,valid):\n","   \n","    \n","    train_dataset = BERTPromptDataset(train[['text']], train['label'], tokenizer)\n","    valid_dataset = BERTPromptDataset(valid[['text']], valid['label'], tokenizer)\n","    sampler = ImbalancedDatasetSampler(train)\n","\n","    \n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n","                              num_workers=2, sampler=sampler, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n","                              num_workers=2, shuffle=False, pin_memory=True)\n","    \n","    return train_loader, valid_loader\n","\n","    \n","    \n","    "]},{"cell_type":"code","execution_count":null,"id":"3b121b13","metadata":{"id":"3b121b13"},"outputs":[],"source":["@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    prediction=[]\n","    true_prediction=[]\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        \n","        text_ids = data['text']\n","#         text_mask = data['text_mask'].to(device, dtype = torch.long)\n","#         mask_pos =data['mask_pos'].to(device, dtype = torch.long)\n","        targets = torch.tensor(data['labels']).to(device, dtype=torch.long)\n","        \n","        batch_size = len(text_ids)\n","\n","        outputs = model(text_ids)\n","        prediction.append(F.softmax(outputs).to('cpu').numpy())\n","        true_prediction.append(targets.to('cpu').numpy())\n","\n","        # outputs = outputs.argmax(dim=1)\n","        \n","        loss = criterion(outputs, targets)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr']) \n","    \n","    gc.collect()\n","    prediction = np.concatenate(prediction)\n","    true_prediction = np.concatenate(true_prediction)\n","    prediction=np.argmax(np.array(prediction),axis=1)\n","    print(print_statistics(np.array(true_prediction),prediction))\n","    print(f1_score(np.array(true_prediction),prediction, average='macro'))\n","\n","    \n","    return epoch_loss, f1_score(np.array(true_prediction),prediction, average='macro')"]},{"cell_type":"code","execution_count":null,"id":"bf3a5464","metadata":{"id":"bf3a5464"},"outputs":[],"source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        \n","        text_ids = data['text']\n","        targets = torch.tensor(data['labels']).to(device, dtype=torch.long)\n","        \n","        batch_size = len(text_ids)\n","        # print(targets)\n","\n","        outputs = model(text_ids)\n","#         print(outputs.shape)\n","#         print(outputs)\n","        \n","        # print(outputs.shape)\n","\n","        \n","        loss = criterion(outputs, targets)\n","        loss = loss / CONFIG['n_accumulate']\n","        loss.backward()\n","    \n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":null,"id":"f1ac4c89","metadata":{"id":"f1ac4c89"},"outputs":[],"source":["from sklearn.metrics import jaccard_score,f1_score,accuracy_score,recall_score,precision_score,classification_report\n","def print_statistics(y, y_pred):\n","    accuracy = accuracy_score(y, y_pred)\n","    precision =precision_score(y, y_pred, average='weighted')\n","    recall = recall_score(y, y_pred, average='weighted')\n","    f_score = f1_score(y, y_pred, average='weighted')\n","    print('Accuracy: %.3f\\nPrecision: %.3f\\nRecall: %.3f\\nF_score: %.3f\\n'\n","          % (accuracy, precision, recall, f_score))\n","    print(classification_report(y, y_pred))\n","    return accuracy, precision, recall, f_score"]},{"cell_type":"markdown","id":"bbe5f6ff","metadata":{"id":"bbe5f6ff"},"source":["# Begin Training"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLrwfn8PUDLk","executionInfo":{"status":"ok","timestamp":1662483427486,"user_tz":-120,"elapsed":57295,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"3028583a-9005-4eb3-d0ce-b4adf2380363"},"id":"fLrwfn8PUDLk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"afeda8b5","metadata":{"id":"afeda8b5"},"outputs":[],"source":["train = pd.read_csv('/content/drive/MyDrive/wanlp/Datasets/NADI2022-Train/NADI2022-Train/Subtask1/NADI2022_Subtask1_TRAIN.tsv', sep='\\t', lineterminator='\\n')\n","valid = pd.read_csv('/content/drive/MyDrive/wanlp/Datasets/NADI2022-Train/NADI2022-Train/Subtask1/NADI2022_Subtask1_DEV.tsv', sep='\\t', lineterminator='\\n')"]},{"cell_type":"code","execution_count":null,"id":"42d2786f","metadata":{"id":"42d2786f"},"outputs":[],"source":["CONFIG = {\"seed\": 42,\n","          \"epochs\": 30,\n","          \"train_batch_size\": 8,\n","          \"valid_batch_size\": 64,\n","          \"max_length\": 512,\n","          \"learning_rate\": 2e-5,\n","          \"scheduler\": 'CosineAnnealingLR',\n","          \"min_lr\": 1e-8,\n","          \"T_max\": 500,\n","          \"weight_decay\": 1e-2,\n","          \"n_fold\": 5,\n","          \"n_accumulate\": 1,\n","          \"num_classes\": 18,\n","          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","          }"]},{"cell_type":"code","execution_count":null,"id":"d07aa098","metadata":{"id":"d07aa098"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","train['#3_label'] = le.fit_transform(train['#3_label'].values)\n","valid['#3_label'] = le.transform(valid['#3_label'].values)\n","train.rename(columns = {'#2_content':'text', '#3_label':'label'}, inplace = True)\n","valid.rename(columns = {'#2_content':'text', '#3_label':'label'}, inplace = True)\n"]},{"cell_type":"code","source":["replicated_0 = pd.concat([train[train['label'] == 0]]*3, ignore_index=True)\n","replicated_1 = pd.concat([train[train['label'] == 1]]*20, ignore_index=True)\n","# # replicated_2 = pd.concat([train[train['label'] == 2]]*8, ignore_index=True)\n","replicated_3 = pd.concat([train[train['label'] == 3]]*2, ignore_index=True)\n","replicated_4 = pd.concat([train[train['label'] == 4]]*10, ignore_index=True)\n","replicated_5 = pd.concat([train[train['label'] == 5]]*2, ignore_index=True)\n","replicated_6 = pd.concat([train[train['label'] == 6]]*10, ignore_index=True)\n","replicated_7 = pd.concat([train[train['label'] == 7]]*9, ignore_index=True)\n","replicated_8 = pd.concat([train[train['label'] == 8]]*4, ignore_index=True)\n","replicated_9 = pd.concat([train[train['label'] == 9]]*5, ignore_index=True)\n","replicated_10 = pd.concat([train[train['label'] == 10]]*3, ignore_index=True)\n","replicated_11 = pd.concat([train[train['label'] == 11]]*10, ignore_index=True)\n","replicated_12 = pd.concat([train[train['label'] == 12]]*20, ignore_index=True)\n","replicated_13 = pd.concat([train[train['label'] == 13]]*20, ignore_index=True)\n","replicated_14 = pd.concat([train[train['label'] == 14]]*4, ignore_index=True)\n","replicated_15 = pd.concat([train[train['label'] == 15]]*5, ignore_index=True)\n","replicated_16 = pd.concat([train[train['label'] == 16]]*9, ignore_index=True)\n","replicated_17 = pd.concat([train[train['label'] == 17]]*10, ignore_index=True)\n","replicated_18 = pd.concat([train[train['label'] == 18]]*20, ignore_index=True)\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"QUByv2-EodLf"},"id":"QUByv2-EodLf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train=pd.concat([train[train['label'] == 2],replicated_18,replicated_17,replicated_16,replicated_15,replicated_14,replicated_13,replicated_12,replicated_11,replicated_10,replicated_9,replicated_8,replicated_7,replicated_6,replicated_5,replicated_4,replicated_3,replicated_1,replicated_0 ])"],"metadata":{"id":"Ud12jF_moeW_"},"id":"Ud12jF_moeW_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.reset_index(inplace=True)"],"metadata":{"id":"MGFu_7pQohoA"},"id":"MGFu_7pQohoA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"3ae768a6","metadata":{"id":"3ae768a6","executionInfo":{"status":"ok","timestamp":1662483447450,"user_tz":-120,"elapsed":12527,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["8c701277e47a4806ba441999c2303ed1","fcc741c989e94891a1ba97ee6973d764","487c6c37c1b047019f09e5d2e21405af","a6b4f3f065ba40f595831d21f32f34f3","30ba4e0d536d4593873264ca2833b516","524a94fea332438e8db8d380fa61934f","c7315d01797d4c08885b9329ec17303c","0531c943e28242cc9f9c476de655a730","6a8aae3de28e431ca55ade8042fb15c8","5c5db6a298024d56899eed55f0c9c886","34ab4889919c4c08be0ba3896a215eb4","12f627afed98453c8a3422261531c504","08600c65d00e43c3914bbea2e5494b98","3788949d5d9b46e296830ec964d2fb35","c05215bb4c1e46fcb56a22093815b4ac","103b9ae23be14219a5982c2bf0736662","4816c61406454af5b6ee14e571b60a46","940f7955537945ed91a3dff8378ce8e9","2acc7dd46e104722a749fdbeedf1dde2","0e685d0db6b64ba1a6cabf653130d5fa","6e07209db2584197ae9f7dfd1bbd93f2","65c5af9ddc734b1a8deab730203ee467","217c53334589419d91067ca20cc493f4","02a1b682b0c647c7a68a69b9f9a3d9cb","74137029abd9450081788817264bfcf1","5be324ee57a64731b5da6cc1911e8815","d2b218b2d2c843cabc62c6b38b695304","5c363811432e4464b7b7402d1f545211","84dded705b924663ad35d0278a0ba493","d25998b6b29b4680815a3dd6469c22d2","c0688aa77c36421a8d8d11bcaa0cfc28","e3e786f652f2406aa6893c707b8e89fb","fd2a699cc4054502ab64a8905663eef8","d9c7e1c9010e4dec840312c0283746d6","9ce05c6967fd42799cf8b231554313bc","856907203c9a443591f4c302a96dd69b","79468447774240b88e8bc9e26b764052","8f2aa6c3b91f443c97023b43c6384579","108f6243dcc24ef7bca7d2fda17087dc","76b23a8593c7449eabe7378c95e42525","cd3bdd263d3b4d4d862f1a5c7c83402f","4c5acb68fc5f49a8bb20e399fb8efb82","78781922a65c481baf8e80f6f5229302","ba0e01fc6fea43999ff3563ab3caec05"]},"outputId":"fad45560-ea4e-4043-a5ad-f3ed340103da"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/476 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c701277e47a4806ba441999c2303ed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/733k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f627afed98453c8a3422261531c504"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.19M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"217c53334589419d91067ca20cc493f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c7e1c9010e4dec840312c0283746d6"}},"metadata":{}}],"source":["tokenizer= AutoTokenizer.from_pretrained('aubmindlab/bert-base-arabertv02-twitter')\n"]},{"cell_type":"code","execution_count":null,"id":"c30a30ca","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192,"referenced_widgets":["bcb9c381ac164b92b319aaf838033bbe","54723a0d117b46aea36aa6861616c254","7df4251f0a854eb0bda66b5f6c6a0239","aafeebfb96cf4d03bef930b268e0a6ce","f1b45149681e431f858edfea02101496","4e1315677928446eaa93dcf2b742ee47","4c6a868a70af45e5a4f4e77b5ff08503","de86cae47f454785a2fe2d04ec34dfc3","68fc17a214d74450bd3ac411826038e0","386f2de9accd405098c91d021052138f","4821e068286c4e7a950dea1ecb32f8f3","4e32bac08d024722843dd2d8e30cf893","1d3b6f9bf3ab4a0ebd02982b43904a28","2acf4d8970c84cb793ebb629370c1c36","1031547f9dfd41fcb0df3324a7e1a1c9","82fb0afb4193453e80364fd5307657f9","6e464b0bbd7b41a1b7a5c6cca93985c9","97e3ac1b60de41678dd817d552bffd4d","e1618bab68b0402baea9f4fdb47f9bb0","a942889cc2724d77b4655d612c3b41d3","527c4885b2614d4184393338a7925bb6","1a25be179c37482aa4534ee4ab0232c0"]},"id":"c30a30ca","executionInfo":{"status":"ok","timestamp":1662483462830,"user_tz":-120,"elapsed":15405,"user":{"displayName":"pink panther","userId":"06900797602742482056"}},"outputId":"886b499c-dad3-4ee2-ebe8-698cb09ad98e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcb9c381ac164b92b319aaf838033bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/516M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e32bac08d024722843dd2d8e30cf893"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["arabert_model=AutoModel.from_pretrained('aubmindlab/bert-base-arabertv02-twitter', output_hidden_states=True)\n"]},{"cell_type":"code","execution_count":null,"id":"be0ec741","metadata":{"id":"be0ec741"},"outputs":[],"source":["pBERT = BERTPrompt(arabert_model, tokenizer, prompt_length=35)\n"]},{"cell_type":"code","execution_count":null,"id":"0b691cd2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0b691cd2","outputId":"ebb08a95-2306-4e4d-e961-019fe96b1216"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU: Tesla T4\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 59/10556 [00:49<2:25:03,  1.21it/s, Epoch=1, LR=1.93e-5, Train_Loss=2.92]"]}],"source":["\n","\n","    \n","# Create Dataloaders\n","train_loader, valid_loader = prepare_loaders(train,valid)\n","\n","pBERT.to(CONFIG['device'])\n","torch.cuda.empty_cache()\n","\n","# Define Optimizer and Scheduler\n","optimizer = AdamW(pBERT.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n","scheduler = fetch_scheduler(optimizer)\n","\n","model, history = run_training(pBERT, optimizer, scheduler,\n","                              device=CONFIG['device'],\n","                              num_epochs=CONFIG['epochs'],\n","                              train_loader=train_loader, valid_loader=valid_loader )\n","\n","\n","del model, history, train_loader, valid_loader\n","_ = gc.collect()\n","print()"]},{"cell_type":"code","execution_count":null,"id":"d2a14011","metadata":{"id":"d2a14011"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"f28d9aa5","metadata":{"id":"f28d9aa5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"f86f6c33","metadata":{"id":"f86f6c33"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9f075632","metadata":{"id":"9f075632"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"536dc8d3","metadata":{"id":"536dc8d3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"84b8d176","metadata":{"id":"84b8d176"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d361ffa7","metadata":{"id":"d361ffa7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a2aecc39","metadata":{"id":"a2aecc39"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6fc6a3ae","metadata":{"id":"6fc6a3ae"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4a97de8e","metadata":{"id":"4a97de8e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4224a8fc","metadata":{"id":"4224a8fc"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"8c701277e47a4806ba441999c2303ed1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcc741c989e94891a1ba97ee6973d764","IPY_MODEL_487c6c37c1b047019f09e5d2e21405af","IPY_MODEL_a6b4f3f065ba40f595831d21f32f34f3"],"layout":"IPY_MODEL_30ba4e0d536d4593873264ca2833b516"}},"fcc741c989e94891a1ba97ee6973d764":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_524a94fea332438e8db8d380fa61934f","placeholder":"​","style":"IPY_MODEL_c7315d01797d4c08885b9329ec17303c","value":"Downloading tokenizer_config.json: 100%"}},"487c6c37c1b047019f09e5d2e21405af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0531c943e28242cc9f9c476de655a730","max":476,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a8aae3de28e431ca55ade8042fb15c8","value":476}},"a6b4f3f065ba40f595831d21f32f34f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5db6a298024d56899eed55f0c9c886","placeholder":"​","style":"IPY_MODEL_34ab4889919c4c08be0ba3896a215eb4","value":" 476/476 [00:00&lt;00:00, 11.1kB/s]"}},"30ba4e0d536d4593873264ca2833b516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"524a94fea332438e8db8d380fa61934f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7315d01797d4c08885b9329ec17303c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0531c943e28242cc9f9c476de655a730":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a8aae3de28e431ca55ade8042fb15c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c5db6a298024d56899eed55f0c9c886":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34ab4889919c4c08be0ba3896a215eb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12f627afed98453c8a3422261531c504":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08600c65d00e43c3914bbea2e5494b98","IPY_MODEL_3788949d5d9b46e296830ec964d2fb35","IPY_MODEL_c05215bb4c1e46fcb56a22093815b4ac"],"layout":"IPY_MODEL_103b9ae23be14219a5982c2bf0736662"}},"08600c65d00e43c3914bbea2e5494b98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4816c61406454af5b6ee14e571b60a46","placeholder":"​","style":"IPY_MODEL_940f7955537945ed91a3dff8378ce8e9","value":"Downloading vocab.txt: 100%"}},"3788949d5d9b46e296830ec964d2fb35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2acc7dd46e104722a749fdbeedf1dde2","max":750551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e685d0db6b64ba1a6cabf653130d5fa","value":750551}},"c05215bb4c1e46fcb56a22093815b4ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e07209db2584197ae9f7dfd1bbd93f2","placeholder":"​","style":"IPY_MODEL_65c5af9ddc734b1a8deab730203ee467","value":" 733k/733k [00:01&lt;00:00, 908kB/s]"}},"103b9ae23be14219a5982c2bf0736662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4816c61406454af5b6ee14e571b60a46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"940f7955537945ed91a3dff8378ce8e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2acc7dd46e104722a749fdbeedf1dde2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e685d0db6b64ba1a6cabf653130d5fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e07209db2584197ae9f7dfd1bbd93f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65c5af9ddc734b1a8deab730203ee467":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"217c53334589419d91067ca20cc493f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02a1b682b0c647c7a68a69b9f9a3d9cb","IPY_MODEL_74137029abd9450081788817264bfcf1","IPY_MODEL_5be324ee57a64731b5da6cc1911e8815"],"layout":"IPY_MODEL_d2b218b2d2c843cabc62c6b38b695304"}},"02a1b682b0c647c7a68a69b9f9a3d9cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c363811432e4464b7b7402d1f545211","placeholder":"​","style":"IPY_MODEL_84dded705b924663ad35d0278a0ba493","value":"Downloading tokenizer.json: 100%"}},"74137029abd9450081788817264bfcf1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d25998b6b29b4680815a3dd6469c22d2","max":1252935,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0688aa77c36421a8d8d11bcaa0cfc28","value":1252935}},"5be324ee57a64731b5da6cc1911e8815":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3e786f652f2406aa6893c707b8e89fb","placeholder":"​","style":"IPY_MODEL_fd2a699cc4054502ab64a8905663eef8","value":" 1.19M/1.19M [00:01&lt;00:00, 749kB/s]"}},"d2b218b2d2c843cabc62c6b38b695304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c363811432e4464b7b7402d1f545211":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84dded705b924663ad35d0278a0ba493":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d25998b6b29b4680815a3dd6469c22d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0688aa77c36421a8d8d11bcaa0cfc28":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3e786f652f2406aa6893c707b8e89fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd2a699cc4054502ab64a8905663eef8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9c7e1c9010e4dec840312c0283746d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ce05c6967fd42799cf8b231554313bc","IPY_MODEL_856907203c9a443591f4c302a96dd69b","IPY_MODEL_79468447774240b88e8bc9e26b764052"],"layout":"IPY_MODEL_8f2aa6c3b91f443c97023b43c6384579"}},"9ce05c6967fd42799cf8b231554313bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_108f6243dcc24ef7bca7d2fda17087dc","placeholder":"​","style":"IPY_MODEL_76b23a8593c7449eabe7378c95e42525","value":"Downloading special_tokens_map.json: 100%"}},"856907203c9a443591f4c302a96dd69b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd3bdd263d3b4d4d862f1a5c7c83402f","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c5acb68fc5f49a8bb20e399fb8efb82","value":112}},"79468447774240b88e8bc9e26b764052":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78781922a65c481baf8e80f6f5229302","placeholder":"​","style":"IPY_MODEL_ba0e01fc6fea43999ff3563ab3caec05","value":" 112/112 [00:00&lt;00:00, 3.58kB/s]"}},"8f2aa6c3b91f443c97023b43c6384579":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"108f6243dcc24ef7bca7d2fda17087dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76b23a8593c7449eabe7378c95e42525":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd3bdd263d3b4d4d862f1a5c7c83402f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c5acb68fc5f49a8bb20e399fb8efb82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78781922a65c481baf8e80f6f5229302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba0e01fc6fea43999ff3563ab3caec05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcb9c381ac164b92b319aaf838033bbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54723a0d117b46aea36aa6861616c254","IPY_MODEL_7df4251f0a854eb0bda66b5f6c6a0239","IPY_MODEL_aafeebfb96cf4d03bef930b268e0a6ce"],"layout":"IPY_MODEL_f1b45149681e431f858edfea02101496"}},"54723a0d117b46aea36aa6861616c254":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1315677928446eaa93dcf2b742ee47","placeholder":"​","style":"IPY_MODEL_4c6a868a70af45e5a4f4e77b5ff08503","value":"Downloading config.json: 100%"}},"7df4251f0a854eb0bda66b5f6c6a0239":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de86cae47f454785a2fe2d04ec34dfc3","max":667,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68fc17a214d74450bd3ac411826038e0","value":667}},"aafeebfb96cf4d03bef930b268e0a6ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_386f2de9accd405098c91d021052138f","placeholder":"​","style":"IPY_MODEL_4821e068286c4e7a950dea1ecb32f8f3","value":" 667/667 [00:00&lt;00:00, 20.4kB/s]"}},"f1b45149681e431f858edfea02101496":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1315677928446eaa93dcf2b742ee47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c6a868a70af45e5a4f4e77b5ff08503":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de86cae47f454785a2fe2d04ec34dfc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68fc17a214d74450bd3ac411826038e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"386f2de9accd405098c91d021052138f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4821e068286c4e7a950dea1ecb32f8f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e32bac08d024722843dd2d8e30cf893":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d3b6f9bf3ab4a0ebd02982b43904a28","IPY_MODEL_2acf4d8970c84cb793ebb629370c1c36","IPY_MODEL_1031547f9dfd41fcb0df3324a7e1a1c9"],"layout":"IPY_MODEL_82fb0afb4193453e80364fd5307657f9"}},"1d3b6f9bf3ab4a0ebd02982b43904a28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e464b0bbd7b41a1b7a5c6cca93985c9","placeholder":"​","style":"IPY_MODEL_97e3ac1b60de41678dd817d552bffd4d","value":"Downloading pytorch_model.bin: 100%"}},"2acf4d8970c84cb793ebb629370c1c36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1618bab68b0402baea9f4fdb47f9bb0","max":541120363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a942889cc2724d77b4655d612c3b41d3","value":541120363}},"1031547f9dfd41fcb0df3324a7e1a1c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_527c4885b2614d4184393338a7925bb6","placeholder":"​","style":"IPY_MODEL_1a25be179c37482aa4534ee4ab0232c0","value":" 516M/516M [00:10&lt;00:00, 59.5MB/s]"}},"82fb0afb4193453e80364fd5307657f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e464b0bbd7b41a1b7a5c6cca93985c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97e3ac1b60de41678dd817d552bffd4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1618bab68b0402baea9f4fdb47f9bb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a942889cc2724d77b4655d612c3b41d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"527c4885b2614d4184393338a7925bb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a25be179c37482aa4534ee4ab0232c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}